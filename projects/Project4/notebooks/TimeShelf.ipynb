{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeShelf: Book Recommendations Across Time and Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.corpora.textcorpus import lower_to_unicode, strip_multiple_whitespaces\n",
    "from gensim.corpora.textcorpus import remove_short, remove_stopwords\n",
    "from gensim import corpora, models, utils\n",
    "from gensim.models.wrappers.dtmmodel import DtmModel\n",
    "from gensim.utils import deaccent, simple_tokenize\n",
    "# from gensim.utils import lemmatize  # Use nltk.stem.WordNetLemmatizer instead\n",
    "# import gutenberg.acquire as gacquire\n",
    "# import gutenberg.query as gquery  # print(gquery.list_supported_metadatas())\n",
    "from hashlib import md5\n",
    "import imp\n",
    "import logging\n",
    "from math import log10\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, isfile\n",
    "from pymongo import MongoClient, InsertOne, DeleteOne, ReplaceOne\n",
    "from random import shuffle\n",
    "import re\n",
    "from sklearn.utils import resample\n",
    "import sys\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config (MongoDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client = MongoClient()\n",
    "assert('local' in mongo_client.database_names())\n",
    "mongo_local_db = mongo_client.local\n",
    "# mongo_local_db.create_collection('timeshelf_config')\n",
    "timeshelf_config = mongo_local_db.get_collection('timeshelf_config')\n",
    "mongo_requests = [InsertOne({'config': 'books_per_decade', 'GUTENBERG_BOOKS_PER_DECADE': 2})\n",
    "                  , InsertOne({'config': 'max_header_lines', 'GUTENBERG_MAX_HEADER_LINES': 300})]\n",
    "mongo_result = mongo_local_db.timeshelf_config.bulk_write(mongo_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[InsertOne({'config': 'books_per_decade', 'GUTENBERG_BOOKS_PER_DECADE': 2, '_id': ObjectId('5aa67cf27aec09f27c0484c1')}),\n",
       " InsertOne({'config': 'max_header_lines', 'GUTENBERG_MAX_HEADER_LINES': 300, '_id': ObjectId('5aa67cf27aec09f27c0484c2')})]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nInserted': 2,\n",
       " 'nMatched': 0,\n",
       " 'nModified': 0,\n",
       " 'nRemoved': 0,\n",
       " 'nUpserted': 0,\n",
       " 'upserted': [],\n",
       " 'writeConcernErrors': [],\n",
       " 'writeErrors': []}"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo_result.bulk_api_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5aa6790b7aec09f27c0484be'), 'GUTENBERG_BOOKS_PER_DECADE': 2}\n",
      "{'_id': ObjectId('5aa6790b7aec09f27c0484bf'), 'GUTENBERG_MAX_HEADER_LINES': 300}\n",
      "{'_id': ObjectId('5aa67cf27aec09f27c0484c1'), 'config': 'books_per_decade', 'GUTENBERG_BOOKS_PER_DECADE': 2}\n",
      "{'_id': ObjectId('5aa67cf27aec09f27c0484c2'), 'config': 'max_header_lines', 'GUTENBERG_MAX_HEADER_LINES': 300}\n"
     ]
    }
   ],
   "source": [
    "for timeshelf_config_doc in timeshelf_config.find():\n",
    "    print(timeshelf_config_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_per_decade = timeshelf_config.find_one({'config': 'books_per_decade'})['GUTENBERG_BOOKS_PER_DECADE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_header_lines = timeshelf_config.find_one({'config': 'max_header_lines'})['GUTENBERG_MAX_HEADER_LINES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_header_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config (Other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTM_PATH = os.environ.get('DTM_PATH', None)\n",
    "if not DTM_PATH:\n",
    "    raise ValueError(\"Error: DTM_PATH must be set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODULE_EXTENSIONS = ('.py', '.pyc', '.pyo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ZHOME = '../data/gutenberg_books_en/aleph.gutenberg.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GUTENBERG_BOOKS_PER_DECADE = 2\n",
    "GUTENBERG_MAX_HEADER_LINES = 300\n",
    "\n",
    "GUTENBERG_DOWNLOAD_DIR = os.environ['GUTENBERG_DOWNLOAD_DIR']\n",
    "GUTENBERG_MIN_DECADE = 1600\n",
    "GUTENBERG_MAX_DECADE = 2010\n",
    "\n",
    "GUTENBERG_STOPWORDS = stopwords.words('english')\n",
    "GUTENBERG_STOPWORDS.extend(gensim.parsing.preprocessing.STOPWORDS)\n",
    "GUTENBERG_STOPWORDS.extend(\"\"\"January February March April May June\n",
    "    July August September October November December\n",
    "    time year\n",
    "    one two three four five six seven eight nine ten\n",
    "    eleven twelve thirteen fourteen fifteen sixteen seventeen eighteen nineteen twenty\n",
    "    \"\"\".lower().split())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_book_data = [ [1, 'Lolita',                             'Vladimir Nabokov',    1955 ]\n",
    "                 , [2, 'The Great Gatsby',                   'F. Scott Fitzgerald', 1925 ]\n",
    "                 , [3, 'In Search of Lost Time',             'Marcel Proust',       1922 ]\n",
    "                 , [4, 'Ulysses',                            'James Joyce',         1922 ]\n",
    "                 , [5, 'Dubliners',                          'James Joyce',         1914 ]\n",
    "                 , [6, 'Anna Karenina',                      'Leo Tolstoy',         1877 ]\n",
    "                 , [7, 'Madame Bovary',                      'Gustave Flaubert',    1857 ]\n",
    "                 , [8, 'War and Peace',                      'Leo Tolstoy',         1869 ]\n",
    "                 , [9, 'The Adventures of Huckleberry Finn', 'Mark Twain',          1884 ]\n",
    "                 , [10, 'Middlemarch',                       'George Eliot',        1871 ]\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Location Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_book_ids = [6001, 7001, 8000, 9043, 10000, 20001, 30000, 40000, 50000]\n",
    "excluded_book_ids = [89, 3290, 5192, 10681, 13526, 15824, 18251]  # Extra download files\n",
    "excluded_book_ids.extend([2609, 16762, 11813, 14021, 29274, 35724, 35335])  # Files out of place\n",
    "excluded_book_ids.extend([1])  # Different format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From https://markroxor.github.io/gensim/static/notebooks/dtm_example.html\n",
    "class DTMcorpus(corpora.textcorpus.TextCorpus):\n",
    "    def get_texts(self):\n",
    "        return self.input\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Upsampling & downsampling to reach GUTENBERG_BOOKS_PER_DECADE\n",
    "class GutenbergCorpus(corpora.textcorpus.TextCorpus):\n",
    "    def __init__(self, books, num_books_per_decade=GUTENBERG_BOOKS_PER_DECADE, seed=0):\n",
    "        self.books = books\n",
    "        self.seed = seed\n",
    "        self.num_books_per_decade = num_books_per_decade\n",
    "        self.set_books_by_decade() # dict: K=int; V=book\n",
    "        self.decades = sorted(self.books_by_decade.keys())\n",
    "        self.set_selected_book_ids_by_decade()\n",
    "\n",
    "        # Creation of the Dictionary uses:\n",
    "        #   0+ character filters\n",
    "        #   a tokenizer\n",
    "        #   0+ token filters\n",
    "        self.character_filters = [lower_to_unicode, deaccent, strip_multiple_whitespaces]\n",
    "        self.tokenizer = simple_tokenize\n",
    "        self.token_filters = [remove_short, remove_stopwords]\n",
    "\n",
    "        self.dictionary = Dictionary(self.get_texts())\n",
    "        self.dictionary.filter_extremes(no_below=2, no_above=0.5, keep_n=100000)\n",
    "        \n",
    "        self.metadata=None\n",
    "\n",
    "    def __len__(self):\n",
    "        # return sum( [len(self.books_by_decade[decade])\n",
    "        #             for decade in self.books_by_decade]\n",
    "        #           )\n",
    "        return self.num_books_per_decade * len(self.decades)\n",
    "    \n",
    "    # Ensure that the texts returned are ordered by decade (i.e., time slice)\n",
    "    # Returned tokens are inserted the instance's dictionary property.\n",
    "    # Note: gensim/corpora/textcorpus.py recommends overriding both get_texts()\n",
    "    #       and getstream(), which is called by get_texts().  Instead of overriding\n",
    "    #       getstream(), we call get_book_content_from_id, which takes care of I/O.\n",
    "    # References: Look at gensim.corpura.wikicorpus for an example of a non-fs-based corpus.\n",
    "    def get_texts(self):\n",
    "        # print(f'Type of items in self.decades: {type(self.decades[0])}')\n",
    "        # print(f'Type of items in self.decades: {type(self.decades[0])}')\n",
    "        for decade in self.decades:\n",
    "            for id in self.selected_book_ids_by_decade[decade]:\n",
    "                content = self.preprocess_text(\n",
    "                    get_book_content_from_id(id, GUTENBERG_STOPWORDS)\n",
    "                )\n",
    "                yield content\n",
    "\n",
    "    def get_time_seq(self):\n",
    "        # Without up- & down-sampling\n",
    "        # return [len(self.decades[decade]) for decade in self.decades]\n",
    "        return [self.num_books_per_decade for decade in self.decades]\n",
    "\n",
    "    def pprint(self):\n",
    "        for decade in self.decades:\n",
    "            print(decade)\n",
    "            for book in self.decades[decade]:\n",
    "                print(f'\\t{book.year}: {book.title}, by {book.author}')\n",
    "\n",
    "    def print_summary(self):\n",
    "        time_seq = self.get_time_seq()\n",
    "        for line in [f'{ts} from the {dec}s' for dec,ts in zip(self.decades, time_seq)]:\n",
    "            print(f'\\t{line}')\n",
    "\n",
    "    def set_books_by_decade(self):\n",
    "        self.books_by_decade = defaultdict(list)\n",
    "        for book in self.books:\n",
    "            dec = get_decade(int(book['year']))\n",
    "            self.books_by_decade[dec].append(book)\n",
    "\n",
    "    def set_selected_book_ids_by_decade(self):\n",
    "        def books2ids(bs):\n",
    "            return list(map(lambda b: int(b['id']), bs))\n",
    "            \n",
    "        self.selected_book_ids_by_decade = defaultdict(list)\n",
    "        for decade in self.decades:\n",
    "            num_books_in_this_decade = len(self.books_by_decade[decade])\n",
    "            if num_books_in_this_decade == self.num_books_per_decade:\n",
    "                # YIELD EACH BOOK IN DECADE\n",
    "                ids = books2ids(self.books_by_decade[decade])\n",
    "                self.selected_book_ids_by_decade[decade] = ids\n",
    "            elif num_books_in_this_decade > self.num_books_per_decade:\n",
    "                # YIELD SUBSET OF BOOKS IN THIS DECADE\n",
    "                ids = books2ids(np.random.choice(self.books_by_decade[decade]\n",
    "                                             , size=self.num_books_per_decade\n",
    "                                             , replace=False))\n",
    "                self.selected_book_ids_by_decade[decade] = ids\n",
    "            else:\n",
    "                ids = books2ids(self.books_by_decade[decade])\n",
    "                # NOT ENOUGH BOOKS: UPSAMPLE WITH REPLACEMENT\n",
    "                upsampled_ids = books2ids(\n",
    "                    resample(self.books_by_decade[decade]\n",
    "                             , replace=True\n",
    "                             , n_samples=self.num_books_per_decade - num_books_in_this_decade\n",
    "                             , random_state=self.seed\n",
    "                            ))\n",
    "                self.selected_book_ids_by_decade[decade] = ids + upsampled_ids\n",
    "\n",
    "        # Shuffle.  Necessary?\n",
    "        for decade in self.decades:\n",
    "            shuffle(self.selected_book_ids_by_decade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_book_content(book_id):\n",
    "    book_path_info = get_book_path_info(book_id, base_dir=GUTENBERG_DOWNLOAD_DIR)\n",
    "    book_path = book_path_info[0]\n",
    "    book = get_book_from_path(book_id, book_path)\n",
    "    return book['content_lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_book_content_from_id(id, stopwords=GUTENBERG_STOPWORDS, do_include_content=True):\n",
    "    book = get_book_from_id(id, do_include_content)\n",
    "    content = ' '.join(book['content_lines'])\n",
    "    return [word for word in content if word not in GUTENBERG_STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_book_from_id(id, do_include_content=True):\n",
    "    book_id_path_info = get_book_id_path_info(id)\n",
    "    book_path = book_id_path_info[1]\n",
    "    book = get_book_from_path(id, book_path, do_include_content)\n",
    "    return book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decade(y):\n",
    "    return 10 * (y // 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Refactor, refactor, refactor\n",
    "# TODO: Refactor special cases into modular components\n",
    "def get_book_from_path(id, zpath, do_include_content=True):\n",
    "    assert(zipfile.is_zipfile(zpath))\n",
    "    if zpath.endswith('-0.zip'):\n",
    "        encoding = 'utf-8'\n",
    "    elif zpath.endswith('-8.zip'):\n",
    "        encoding = 'latin-1'  # 'iso-8559-1', 'iso8559-1', '8559'\n",
    "    else:\n",
    "        encoding = 'ascii'\n",
    "\n",
    "    line_number = None\n",
    "    with zipfile.ZipFile(zpath, 'r') as zfile:\n",
    "        # print('Opened zip file')\n",
    "        txtfiles = [fname for fname in zfile.namelist() if fname.lower().endswith('.txt')]\n",
    "        # print(f'txtfiles={txtfiles}')\n",
    "        if len(txtfiles) != 1:\n",
    "            # print(f'Non-unique file for zpath={zpath}')\n",
    "            return { 'id': id\n",
    "                    , 'path': zpath\n",
    "                    , 'author': None\n",
    "                    , 'title': None\n",
    "                    , 'year': None\n",
    "                    , 'content_lines': None\n",
    "                    , 'error': 'Non-unique text file'\n",
    "                   }\n",
    "        with zfile.open(txtfiles[0], 'r') as tfile:\n",
    "            # print('Opened book contents within zip file')\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            have_seen_start_content_line = False\n",
    "            have_seen_end_content_line = False\n",
    "            is_in_header_paragraph = False\n",
    "            content_start_line_num = 0\n",
    "            content_end_line_num = sys.maxsize\n",
    "            author = None\n",
    "            title = None\n",
    "            year = 0\n",
    "            error = ''\n",
    "            # print(f'type(tfile)={type(tfile)}')\n",
    "            try:\n",
    "                lines = [line.decode('utf-8').strip() for line in tfile.readlines()]\n",
    "            except Exception as ex:\n",
    "                return { 'id': id\n",
    "                        , 'path': zpath\n",
    "                        , 'author': author\n",
    "                        , 'title': title\n",
    "                        , 'year': year\n",
    "                        , 'content_lines': None\n",
    "                        , 'error': 'Could not decode file'\n",
    "                       }\n",
    "            title_excluded_re = re.compile('(census|dictionary|encyclo|fable|gutenberg|senate)')\n",
    "            title_digits_re = re.compile('(\\d{4})')\n",
    "            gutenberg_re = re.compile('utenberg')\n",
    "            blank_re = re.compile('^\\s*$')\n",
    "            author_re = re.compile('^Author: (.*)$')\n",
    "            release_year_re = re.compile('^Release Date: [^,]+, (\\d{4})')\n",
    "            title_re = re.compile('^Title: (.*)$')\n",
    "            start_content_re = re.compile('^\\*\\*\\*\\s*START')\n",
    "            end_small_print_re = re.compile('^\\*END\\*THE SMALL PRINT')\n",
    "            end_content1_re = re.compile('^\\*\\*\\*\\s*END')\n",
    "            end_content2_re = re.compile('^End of the Project')\n",
    "            \n",
    "            # Case 0: Year on first row\n",
    "            year_anywhere_re = re.compile('[^\\d](\\d{4})[^\\d]')\n",
    "            # Case 1: Year alone on a line with white space (and perhaps a period)\n",
    "            year_own_line_re = re.compile('^\\s*(\\d{4})\\.?\\s*$')\n",
    "            # Case 2: Year taggled with string: edition, copyright, (c), year, published,\n",
    "            #                           transcribed, or full month name\n",
    "            year_tagged_re = re.compile('(copyright|\\(c\\)|edition|published|transcribed|year|january|february|march|april|may|june|july|august|september|october|november|december)')\n",
    "            # Case 3: Year within parentheses\n",
    "            year_parens_re = re.compile('\\((\\d{4})\\)')\n",
    "            \n",
    "            # print('About to iterate through book content lines')\n",
    "            for line_num, line in enumerate(lines):\n",
    "                line_number = line_num\n",
    "\n",
    "                if line_num == 0:\n",
    "                    # Case 0: Year on first row\n",
    "                    year_anywhere_m = year_anywhere_re.search(line)\n",
    "                    if year_anywhere_m:\n",
    "                        year = year_anywhere_m.group(1)\n",
    "\n",
    "                if line_num < GUTENBERG_MAX_HEADER_LINES:\n",
    "                    if not have_seen_end_content_line:\n",
    "                        start_content_m = start_content_re.match(line)\n",
    "                        if start_content_m:\n",
    "                            have_seen_start_content_line = True\n",
    "                            # Start content after START marker\n",
    "                            content_start_line_num = line_num + 1\n",
    "                        end_small_print_m = end_small_print_re.match(line)\n",
    "                        if end_small_print_m:\n",
    "                            # Start content after end of small print\n",
    "                            content_start_line_num = line_num + 1\n",
    "                    if have_seen_start_content_line and gutenberg_re.search(line):\n",
    "                        is_in_header_paragraph = True\n",
    "                    if is_in_header_paragraph and blank_re.match(line):\n",
    "                        is_in_header_paragraph = False\n",
    "                        # Start content at next non-Gutenberg line\n",
    "                        content_start_line_num = line_num + 1\n",
    "\n",
    "                    author_m = author_re.match(line)\n",
    "                    if author_m:\n",
    "                        author = author_m.group(1)\n",
    "\n",
    "                    # release_year_m = release_year_re.match(line)\n",
    "                    # if release_year_m:\n",
    "                    #     year = release_year_m.group(1)\n",
    "\n",
    "                    title_m = title_re.match(line)         \n",
    "                    if title_m:\n",
    "                        title = title_m.group(1)\n",
    "                        title_excluded_m = title_excluded_re.search(line.lower())\n",
    "                        title_digits_m = year_anywhere_re.search(line)\n",
    "                        if title_excluded_m or title_digits_m:\n",
    "                            return { 'id': id\n",
    "                                    , 'path': zpath\n",
    "                                    , 'author': author\n",
    "                                    , 'title': title\n",
    "                                    , 'year': year\n",
    "                                    , 'content_lines':\n",
    "                                        (lines[content_start_line_num:content_end_line_num]\n",
    "                                         if do_include_content else None\n",
    "                                        )\n",
    "                                    , 'error': f'Excluded due to title'\n",
    "                                }\n",
    "\n",
    "                    if year == 0:\n",
    "                        # Case 1: Year alone on a line with white space (and perhaps a period)\n",
    "                        year_own_line_m = year_own_line_re.match(line)\n",
    "                        if year_own_line_m:\n",
    "                            year = year_own_line_m.group(1)\n",
    "                        else:\n",
    "                            # Case 2: Year tagged with string\n",
    "                            year_tagged_m = year_tagged_re.search(line.lower())\n",
    "                            release_year_m = release_year_re.match(line)\n",
    "                            if year_tagged_m and not release_year_m:\n",
    "                                # Find the year itself\n",
    "                                year_anywhere_m = year_anywhere_re.search(line)\n",
    "                                if year_anywhere_m:\n",
    "                                    year = year_anywhere_m.group(1)\n",
    "                            else:\n",
    "                                # Case 3: Year within parentheses\n",
    "                                year_parens_m = year_parens_re.search(line)\n",
    "                                if year_parens_m:\n",
    "                                    year = year_parens_m.group(1)\n",
    "\n",
    "                end_content1_m = end_content1_re.match(line)\n",
    "                end_content2_m = end_content2_re.match(line)\n",
    "                if end_content1_m or end_content2_m:\n",
    "                    content_end_line_num = line_num\n",
    "                    have_seen_end_content_line = True\n",
    "                    # print(f'Found end content tag at line {line_num}; content_end_line_num={content_end_line_num}')\n",
    "                    break\n",
    "\n",
    "            # print(f'seen_start={have_seen_start_content_line}; author={author}; title={title}; year={year}')\n",
    "            if is_in_header_paragraph:\n",
    "                error += f'{line_number}: Still in header paragraph. '\n",
    "            if not have_seen_start_content_line:\n",
    "                error += f'{line_number}: Start content line not found. '\n",
    "            if not author:\n",
    "                error += f'{line_number}: Author not found. '\n",
    "            if not title:\n",
    "                error += f'{line_number}: Title not found. '\n",
    "            if year == 0:\n",
    "                error += f'{line_number}: Year not found. '\n",
    "            if not have_seen_end_content_line:\n",
    "                error += f'{line_number}: End content line not found. '\n",
    "            return { 'id': id\n",
    "                    , 'path': zpath\n",
    "                    , 'author': author\n",
    "                    , 'title': title\n",
    "                    , 'year': year\n",
    "                    , 'content_lines':\n",
    "                        map(lemmatizer.lemmatize\n",
    "                            , lines[content_start_line_num:content_end_line_num])\n",
    "                        if do_include_content else None           \n",
    "                    , 'error': error\n",
    "                    }\n",
    "            # End of zfile context manager block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_ids(base_dir=None, excluded_book_ids=[]):\n",
    "    if not base_dir:\n",
    "        base_dir = GUTENBERG_DOWNLOAD_DIR\n",
    "    book_id_strs = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if len(files) > 0:\n",
    "            zip_files = list(filter(lambda fname: fname.endswith('.zip'), files))\n",
    "            if len(zip_files) > 0:\n",
    "                book_id_str = zip_files[0]\n",
    "                hyphen_ind = book_id_str.find('-')\n",
    "                if hyphen_ind > -1:\n",
    "                    book_id_str = book_id_str[:hyphen_ind]\n",
    "                else:\n",
    "                    zip_ind = book_id_str.find('.zip')\n",
    "                    book_id_str = book_id_str[:zip_ind]\n",
    "                if int(book_id_str) in excluded_book_ids:\n",
    "                    continue\n",
    "                book_id_strs.append(book_id_str)\n",
    "    book_ids = [int(id_str) for id_str in book_id_strs]\n",
    "    return [book_id for book_id in book_ids if book_id not in excluded_book_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_book_id_path_info(id, base_dir=None):\n",
    "    if not base_dir:\n",
    "        base_dir = GUTENBERG_DOWNLOAD_DIR\n",
    "    \"\"\"Returns (path, error_string)\"\"\"\n",
    "    if id in excluded_book_ids:\n",
    "        return (id, None, 'Excluded book id')\n",
    "    id_str = str(id)\n",
    "    segments = list(id_str)[:-1]\n",
    "    if len(segments) == 0:\n",
    "        segments.insert(0, '0')\n",
    "    if not base_dir.endswith('/'):\n",
    "        base_dir = base_dir + '/'\n",
    "    dir_path = base_dir + '/'.join(segments) + '/' + id_str + '/'\n",
    " \n",
    "    try:\n",
    "        assert(isdir(dir_path))\n",
    "    except Exception as ex:\n",
    "        return (id, None, 'A=' + str(ex))   \n",
    "    \n",
    "    files = listdir(dir_path)\n",
    "\n",
    "    try: \n",
    "        assert(len(files) > 0)\n",
    "    except Exception as ex:\n",
    "        return (id, None, 'B=' + str(ex))\n",
    "\n",
    "    if len(files) == 1:\n",
    "        return (id, dir_path + files[0], '')\n",
    "\n",
    "    no_hyphens = list(filter(lambda s: not '-' in s, files))\n",
    "    if len(no_hyphens) > 0:\n",
    "        return (id, dir_path + no_hyphens[0], '')\n",
    "\n",
    "    dash_zeros = list(filter(lambda s: '-0' in s, files))\n",
    "    if len(dash_zeros) > 0:\n",
    "        return (id, dir_path + dash_zeros[0], '')\n",
    "\n",
    "    dash_eights = list(filter(lambda s: '-8' in s, files))\n",
    "    if len(dash_eights) > 0:\n",
    "        return (id, dir_path + dash_eights[0], '')\n",
    "\n",
    "    return (id, None, 'No file with expected filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_get_book(book_id):\n",
    "    book_path_info = get_book_path_info(book_id, base_dir=GUTENBERG_DOWNLOAD_DIR)\n",
    "    if not book_path_info[0]:\n",
    "        print(f'Book #{book_id}: {book_path_info[1]}')\n",
    "        return None\n",
    "    book_path = book_path_info[0]\n",
    "    book = get_book_from_path(book_id, book_path)\n",
    "    return book  # print(f\"book_id={book_id} has {len(book['content_lines'])} lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lda():\n",
    "    p_stemmer = PorterStemmer()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    test_books = [get_book_from_id(id) for id in [101,300,400,500,600,700,804,902]]\n",
    "    test_docs = [' '.join(b['content_lines']) for b in test_books]\n",
    "    # print(f\"Titles: {[b['title'] for b in test_books]}\")\n",
    "    # print(f\"Years: {[b['year'] for b in test_books]}\")\n",
    "\n",
    "    test_texts = []\n",
    "    for doc in test_docs:\n",
    "        # clean and tokenize document string\n",
    "        raw = doc.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        valid_tokens = [t for t in tokens if not t in stop_words]\n",
    "        stemmed_tokens = [p_stemmer.stem(st) for st in valid_tokens]\n",
    "        test_texts.append(stemmed_tokens)\n",
    "\n",
    "    test_dictionary = corpora.Dictionary(test_texts)\n",
    "    test_dictionary.filter_extremes(no_below=2, no_above=0.5, keep_n=100000)\n",
    "    test_bow = [test_dictionary.doc2bow(text) for text in test_texts]\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(test_bow\n",
    "                                               , alpha='auto'\n",
    "                                               , id2word=test_dictionary\n",
    "                                               , num_topics=20\n",
    "                                               , passes=20)\n",
    "\n",
    "    return ldamodel\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7,\n",
       "  '0.000*\"brass\" + 0.000*\"kit\" + 0.000*\"la\" + 0.000*\"board\" + 0.000*\"secur\" + 0.000*\"dwarf\" + 0.000*\"fairi\" + 0.000*\"crime\" + 0.000*\"law\" + 0.000*\"commun\"'),\n",
       " (3,\n",
       "  '0.000*\"kit\" + 0.000*\"brass\" + 0.000*\"board\" + 0.000*\"dwarf\" + 0.000*\"ha\" + 0.000*\"richard\" + 0.000*\"salli\" + 0.000*\"document\" + 0.000*\"barbara\" + 0.000*\"law\"'),\n",
       " (16,\n",
       "  '0.000*\"board\" + 0.000*\"kit\" + 0.000*\"brass\" + 0.000*\"underground\" + 0.000*\"secur\" + 0.000*\"law\" + 0.000*\"group\" + 0.000*\"crime\" + 0.000*\"g\" + 0.000*\"polic\"'),\n",
       " (14,\n",
       "  '0.000*\"kit\" + 0.000*\"board\" + 0.000*\"brass\" + 0.000*\"underground\" + 0.000*\"commun\" + 0.000*\"crime\" + 0.000*\"simpli\" + 0.000*\"polic\" + 0.000*\"secur\" + 0.000*\"salli\"'),\n",
       " (17,\n",
       "  '0.000*\"kit\" + 0.000*\"brass\" + 0.000*\"richard\" + 0.000*\"dwarf\" + 0.000*\"barbara\" + 0.000*\"law\" + 0.000*\"salli\" + 0.000*\"secur\" + 0.000*\"board\" + 0.000*\"ha\"'),\n",
       " (12,\n",
       "  '0.016*\"simpli\" + 0.008*\"law\" + 0.007*\"conscious\" + 0.007*\"insult\" + 0.005*\"underground\" + 0.005*\"nasti\" + 0.004*\"honour\" + 0.004*\"forgiv\" + 0.004*\"normal\" + 0.004*\"sublim\"'),\n",
       " (5,\n",
       "  '0.032*\"rocket\" + 0.024*\"giant\" + 0.011*\"student\" + 0.011*\"rat\" + 0.011*\"duck\" + 0.011*\"selfish\" + 0.010*\"linnet\" + 0.009*\"statu\" + 0.009*\"thorn\" + 0.008*\"river\"'),\n",
       " (18,\n",
       "  '0.017*\"facsimil\" + 0.013*\"document\" + 0.004*\"unit\" + 0.004*\"file\" + 0.004*\"research\" + 0.004*\"remov\" + 0.004*\"parchment\" + 0.004*\"copyright\" + 0.004*\"plethora\" + 0.004*\"1971\"'),\n",
       " (8,\n",
       "  '0.017*\"board\" + 0.010*\"g\" + 0.009*\"secur\" + 0.009*\"polic\" + 0.009*\"crime\" + 0.009*\"document\" + 0.008*\"underground\" + 0.007*\"commun\" + 0.007*\"group\" + 0.007*\"inform\"'),\n",
       " (15,\n",
       "  '0.023*\"kit\" + 0.017*\"brass\" + 0.008*\"dwarf\" + 0.007*\"richard\" + 0.006*\"salli\" + 0.005*\"barbara\" + 0.005*\"ha\" + 0.004*\"grandfath\" + 0.004*\"la\" + 0.003*\"notari\"')]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_ldamodel = test_lda()\n",
    "# test_ldamodel.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample use: util_package_contents('nltk')\n",
    "def util_package_contents(package_name):\n",
    "    file, pathname, description = imp.find_module(package_name)\n",
    "    if file:\n",
    "        raise ImportError('Not a package: %r', package_name)\n",
    "    # Use a set because some may be both source and compiled.\n",
    "    return set([os.path.splitext(module)[0]\n",
    "                for module in os.listdir(pathname)\n",
    "                if module.endswith(MODULE_EXTENSIONS)\n",
    "               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary demo of GutenbergBook Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demo():\n",
    "    gbooks = list(map(lambda data: GutenbergBook(*data), test_book_data))\n",
    "    gcorpus = GutenbergCorpus(gbooks)\n",
    "    gcorpus.pprint()\n",
    "    print()\n",
    "    print(gcorpus.books_by_decade.keys())\n",
    "    print(gcorpus.get_time_seq())\n",
    "    print()\n",
    "    print('Summary:')\n",
    "    gcorpus.print_summary()\n",
    "    print()\n",
    "\n",
    "    #for text in gcorpus.get_texts():\n",
    "    #    print('=== PROJECT GUTENBERG TEXT ===')\n",
    "    #    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850\n",
      "\t1857: Madame Bovary, by Gustave Flaubert\n",
      "1860\n",
      "\t1869: War and Peace, by Leo Tolstoy\n",
      "1870\n",
      "\t1877: Anna Karenina, by Leo Tolstoy\n",
      "\t1871: Middlemarch, by George Eliot\n",
      "1880\n",
      "\t1884: The Adventures of Huckleberry Finn, by Mark Twain\n",
      "1910\n",
      "\t1914: Dubliners, by James Joyce\n",
      "1920\n",
      "\t1925: The Great Gatsby, by F. Scott Fitzgerald\n",
      "\t1922: In Search of Lost Time, by Marcel Proust\n",
      "\t1922: Ulysses, by James Joyce\n",
      "1950\n",
      "\t1955: Lolita, by Vladimir Nabokov\n",
      "\n",
      "[1850, 1860, 1870, 1880, 1910, 1920, 1950]\n",
      "[1, 1, 2, 1, 1, 3, 1]\n",
      "\n",
      "Summary:\n",
      "\t1 from the 1850s\n",
      "\t1 from the 1860s\n",
      "\t2 from the 1870s\n",
      "\t1 from the 1880s\n",
      "\t1 from the 1910s\n",
      "\t3 from the 1920s\n",
      "\t1 from the 1950s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Books Available for Corpus Membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbook_ids = get_book_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39684"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gbook_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbook_id_path_infos = [get_book_id_path_info(id) for id in gbook_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39684"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gbook_id_path_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbook_id_paths = [(id, path) for id, path, error in gbook_id_path_infos\n",
    "                  if error == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39663"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gbook_id_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-unique file for zpath=/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/0/4/6/10464/10464.zip\n"
     ]
    }
   ],
   "source": [
    "gbooks = [get_book_from_path(id, path, do_include_content=False)\n",
    "          for (id, path) in gbook_id_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbooks_valid = [book for book in gbooks\n",
    "                if book['error'] == ''\n",
    "                    and (book['year'] is not None)\n",
    "                    and int(book['year']) >= GUTENBERG_MIN_DECADE\n",
    "                    and int(book['year']) <= GUTENBERG_MAX_DECADE\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34978"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gbooks_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_cntr = Counter([get_decade(int(book['year']))\n",
    "                                        for book in gbooks_valid\n",
    "                                        if int(book['year']) <= 2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decade_cntr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600s: 2\n",
      "1630s: 2\n",
      "1640s: 1\n",
      "1650s: 1\n",
      "1660s: 46\n",
      "1670s: 1\n",
      "1680s: 1\n",
      "1690s: 1\n",
      "1700s: 1\n",
      "1710s: 1\n",
      "1720s: 3\n",
      "1730s: 2\n",
      "1740s: 8\n",
      "1750s: 6\n",
      "1760s: 4\n",
      "1770s: 9\n",
      "1780s: 8\n",
      "1790s: 5\n",
      "1800s: 7\n",
      "1810s: 16\n",
      "1820s: 73\n",
      "1830s: 52\n",
      "1840s: 121\n",
      "1850s: 208\n",
      "1860s: 124\n",
      "1870s: 106\n",
      "1880s: 246\n",
      "1890s: 460\n",
      "1900s: 120\n",
      "1910s: 227\n",
      "1920s: 72\n",
      "1930s: 23\n",
      "1940s: 5\n",
      "1950s: 3\n",
      "1960s: 1\n",
      "1970s: 3\n",
      "1980s: 1\n",
      "1990s: 212\n",
      "2000s: 18124\n",
      "2010s: 14668\n"
     ]
    }
   ],
   "source": [
    "for decade in sorted(decade_cntr.keys()):\n",
    "    print(f'{decade}s: {decade_cntr[decade]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Diary of Samuel Pepys, June/July 1668',\n",
       " 'Diary of Samuel Pepys, 1669',\n",
       " 'Diary of Samuel Pepys, Apr/May 1669',\n",
       " 'Diary of Samuel Pepys, August 1668',\n",
       " 'Diary of Samuel Pepys, November 1668',\n",
       " 'Diary of Samuel Pepys, December 1668',\n",
       " 'Diary of Samuel Pepys, 1668',\n",
       " 'Diary of Samuel Pepys, July 1667',\n",
       " 'Diary of Samuel Pepys, 1666',\n",
       " 'Diary of Samuel Pepys, May 1667',\n",
       " 'Diary of Samuel Pepys, June 1667',\n",
       " 'Diary of Samuel Pepys, December 1666',\n",
       " 'Diary of Samuel Pepys, August 1667',\n",
       " 'Diary of Samuel Pepys, May/June 1666',\n",
       " 'Diary of Samuel Pepys, 1665',\n",
       " 'Diary of Samuel Pepys, October 1665',\n",
       " 'Diary of Samuel Pepys, November 1666',\n",
       " 'Diary of Samuel Pepys, October 1666',\n",
       " 'Diary of Samuel Pepys, July 1666',\n",
       " 'Diary of Samuel Pepys, November 1667',\n",
       " 'Diary of Samuel Pepys, December 1667',\n",
       " 'Diary of Samuel Pepys, 1667',\n",
       " 'Diary of Samuel Pepys, April 1668',\n",
       " 'Diary of Samuel Pepys, October 1667',\n",
       " 'Diary of Samuel Pepys, September 1667',\n",
       " 'Diary of Samuel Pepys, May 1668',\n",
       " 'Diary of Samuel Pepys, June/July 1664',\n",
       " 'Diary of Samuel Pepys, April/May 1664',\n",
       " 'Diary of Samuel Pepys, May/June 1663',\n",
       " 'Diary of Samuel Pepys, July/August 1663',\n",
       " 'Diary of Samuel Pepys, 1663',\n",
       " 'Diary of Samuel Pepys, 1661',\n",
       " 'Diary of Samuel Pepys, 1662',\n",
       " 'Diary of Samuel Pepys, May/June 1662',\n",
       " 'Diary of Samuel Pepys, July/August 1662',\n",
       " 'Diary of Samuel Pepys, June/July 1660',\n",
       " 'Diary of Samuel Pepys, 1660',\n",
       " 'Diary of Samuel Pepys, October/November/December 1660',\n",
       " 'Diary of Samuel Pepys, May 1660',\n",
       " 'Diary of Samuel Pepys, April/May 1661',\n",
       " 'Diary of Samuel Pepys, December 1664',\n",
       " 'Diary of Samuel Pepys, 1664',\n",
       " 'Diary of Samuel Pepys, August 1665',\n",
       " 'Diary of Samuel Pepys, May/June 1665',\n",
       " 'Diary of Samuel Pepys, July 1665',\n",
       " 'Diary of Samuel Pepys, September 1665']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[book['title'] for book in gbooks_valid if get_decade(int(book['year'])) == 1660]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34974"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([v for k, v in decade_cntr.items() if k >= GUTENBERG_MIN_DECADE and k <= GUTENBERG_MAX_DECADE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_logp1 = [(k, 1 + log10(decade_cntr[k]))\n",
    "                for k in sorted(decade_cntr.keys())\n",
    "                if k >= GUTENBERG_MIN_DECADE and k <= GUTENBERG_MAX_DECADE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEYCAYAAABV8iGRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRzkDMDPrUc4AzMx6lDMAM7Me9b/VAYZx2w9fcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a22431a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gxlabels = [p[0] for p in decade_logp1]\n",
    "gyvalues = [p[1] for p in decade_logp1]\n",
    "gwidth = 6\n",
    "plt.bar(gxlabels, gyvalues, gwidth)\n",
    "ax = plt.gca()\n",
    "ax.set_title('Gutenberg Book Count ($1 + log_{10}$) by Decade')\n",
    "ax.set_xlabel('Year of publication')\n",
    "ax.set_ylabel('Gutenberg book count ($1 + log_{10}$)')\n",
    "plt.xlim(xmin=1590, xmax=2020)\n",
    "ax.xaxis.set_ticks(np.arange(1600, 2011, 50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(72791 unique tokens: ['_ad', '_ad_', '_aesop', '_almanack_', '_almanacks_']...) from 80 documents (total 1429573 corpus positions)\n",
      "INFO:gensim.corpora.dictionary:discarding 37845 tokens: [('_ad_', 1), ('_almanacks_', 1), ('_alpha_', 1), ('_although', 1), ('_amant', 1), ('_ambo', 1), ('_anglice_', 1), ('_anglicus_', 1), ('_annas', 1), ('_annotation_', 1)]...\n",
      "INFO:gensim.corpora.dictionary:keeping 34946 tokens which were in no less than 2 and no more than 40 (=50.0%) documents\n",
      "DEBUG:gensim.corpora.dictionary:rebuilding dictionary, shrinking gaps\n",
      "INFO:gensim.corpora.dictionary:resulting dictionary: Dictionary(34946 unique tokens: ['_ad', '_aesop', '_almanack_', '_an_', '_and']...)\n"
     ]
    }
   ],
   "source": [
    "gcorpus = GutenbergCorpus(gbooks_valid\n",
    "                          , num_books_per_decade=GUTENBERG_BOOKS_PER_DECADE\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600: [15835, 48594]\n",
      "1630: [12259, 38417]\n",
      "1640: [47462, 47462]\n",
      "1650: [9198, 9198]\n",
      "1660: [4170, 4168]\n",
      "1670: [28010, 28010]\n",
      "1680: [16335, 16335]\n",
      "1690: [13274, 13274]\n",
      "1700: [36587, 36587]\n",
      "1710: [12381, 12381]\n",
      "1720: [31673, 16299]\n",
      "1730: [2108, 2822]\n",
      "1740: [18635, 2116]\n",
      "1750: [3355, 2119]\n",
      "1760: [30099, 16747]\n",
      "1770: [14611, 49742]\n",
      "1780: [45757, 22487]\n",
      "1790: [8639, 41144]\n",
      "1800: [11866, 44408]\n",
      "1810: [11203, 44281]\n",
      "1820: [42482, 11460]\n",
      "1830: [43540, 11903]\n",
      "1840: [11454, 25633]\n",
      "1850: [37516, 36124]\n",
      "1860: [20647, 15819]\n",
      "1870: [10014, 25725]\n",
      "1880: [29134, 15924]\n",
      "1890: [12905, 32976]\n",
      "1900: [25107, 23411]\n",
      "1910: [26377, 28470]\n",
      "1920: [20779, 16684]\n",
      "1930: [46222, 41622]\n",
      "1940: [41651, 45185]\n",
      "1950: [25034, 19780]\n",
      "1960: [15158, 15158]\n",
      "1970: [30557, 5]\n",
      "1980: [4290, 4290]\n",
      "1990: [1405, 1729]\n",
      "2000: [21899, 3871]\n",
      "2010: [34230, 32331]\n"
     ]
    }
   ],
   "source": [
    "for decade in gcorpus.decades:\n",
    "    print(f'{decade}: {gcorpus.selected_book_ids_by_decade[decade]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1600,\n",
       " 1630,\n",
       " 1640,\n",
       " 1650,\n",
       " 1660,\n",
       " 1670,\n",
       " 1680,\n",
       " 1690,\n",
       " 1700,\n",
       " 1710,\n",
       " 1720,\n",
       " 1730,\n",
       " 1740,\n",
       " 1750,\n",
       " 1760,\n",
       " 1770,\n",
       " 1780,\n",
       " 1790,\n",
       " 1800,\n",
       " 1810,\n",
       " 1820,\n",
       " 1830,\n",
       " 1840,\n",
       " 1850,\n",
       " 1860,\n",
       " 1870,\n",
       " 1880,\n",
       " 1890,\n",
       " 1900,\n",
       " 1910,\n",
       " 1920,\n",
       " 1930,\n",
       " 1940,\n",
       " 1950,\n",
       " 1960,\n",
       " 1970,\n",
       " 1980,\n",
       " 1990,\n",
       " 2000,\n",
       " 2010]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcorpus.decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcorpus.get_time_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {1600: [15835, 48594],\n",
       "             1630: [12259, 38417],\n",
       "             1640: [47462, 47462],\n",
       "             1650: [9198, 9198],\n",
       "             1660: [4170, 4168],\n",
       "             1670: [28010, 28010],\n",
       "             1680: [16335, 16335],\n",
       "             1690: [13274, 13274],\n",
       "             1700: [36587, 36587],\n",
       "             1710: [12381, 12381],\n",
       "             1720: [31673, 16299],\n",
       "             1730: [2108, 2822],\n",
       "             1740: [18635, 2116],\n",
       "             1750: [3355, 2119],\n",
       "             1760: [30099, 16747],\n",
       "             1770: [14611, 49742],\n",
       "             1780: [45757, 22487],\n",
       "             1790: [8639, 41144],\n",
       "             1800: [11866, 44408],\n",
       "             1810: [11203, 44281],\n",
       "             1820: [42482, 11460],\n",
       "             1830: [43540, 11903],\n",
       "             1840: [11454, 25633],\n",
       "             1850: [37516, 36124],\n",
       "             1860: [20647, 15819],\n",
       "             1870: [10014, 25725],\n",
       "             1880: [29134, 15924],\n",
       "             1890: [12905, 32976],\n",
       "             1900: [25107, 23411],\n",
       "             1910: [26377, 28470],\n",
       "             1920: [20779, 16684],\n",
       "             1930: [46222, 41622],\n",
       "             1940: [41651, 45185],\n",
       "             1950: [25034, 19780],\n",
       "             1960: [15158, 15158],\n",
       "             1970: [30557, 5],\n",
       "             1980: [4290, 4290],\n",
       "             1990: [1405, 1729],\n",
       "             2000: [21899, 3871],\n",
       "             2010: [34230, 32331],\n",
       "             34: [],\n",
       "             39: [],\n",
       "             1: [],\n",
       "             38: [],\n",
       "             8: [],\n",
       "             37: [],\n",
       "             24: [],\n",
       "             36: [],\n",
       "             6: [],\n",
       "             35: [],\n",
       "             28: [],\n",
       "             29: [],\n",
       "             33: [],\n",
       "             19: [],\n",
       "             32: [],\n",
       "             2: [],\n",
       "             31: [],\n",
       "             10: [],\n",
       "             30: [],\n",
       "             26: [],\n",
       "             27: [],\n",
       "             9: [],\n",
       "             25: [],\n",
       "             17: [],\n",
       "             23: [],\n",
       "             18: [],\n",
       "             22: [],\n",
       "             20: [],\n",
       "             21: [],\n",
       "             7: [],\n",
       "             16: [],\n",
       "             15: [],\n",
       "             13: [],\n",
       "             14: [],\n",
       "             5: [],\n",
       "             12: [],\n",
       "             11: [],\n",
       "             4: [],\n",
       "             3: [],\n",
       "             0: [],\n",
       "             79: [],\n",
       "             60: [],\n",
       "             78: [],\n",
       "             68: [],\n",
       "             77: [],\n",
       "             59: [],\n",
       "             76: [],\n",
       "             75: [],\n",
       "             74: [],\n",
       "             73: [],\n",
       "             72: [],\n",
       "             52: [],\n",
       "             71: [],\n",
       "             70: [],\n",
       "             69: [],\n",
       "             63: [],\n",
       "             67: [],\n",
       "             66: [],\n",
       "             65: [],\n",
       "             64: [],\n",
       "             44: [],\n",
       "             62: [],\n",
       "             61: [],\n",
       "             58: [],\n",
       "             57: [],\n",
       "             56: [],\n",
       "             55: [],\n",
       "             54: [],\n",
       "             53: [],\n",
       "             51: [],\n",
       "             50: [],\n",
       "             49: [],\n",
       "             48: [],\n",
       "             47: [],\n",
       "             46: [],\n",
       "             45: [],\n",
       "             43: [],\n",
       "             42: [],\n",
       "             41: [],\n",
       "             40: [],\n",
       "             109: [],\n",
       "             119: [],\n",
       "             104: [],\n",
       "             118: [],\n",
       "             117: [],\n",
       "             100: [],\n",
       "             116: [],\n",
       "             115: [],\n",
       "             114: [],\n",
       "             113: [],\n",
       "             112: [],\n",
       "             111: [],\n",
       "             110: [],\n",
       "             108: [],\n",
       "             107: [],\n",
       "             106: [],\n",
       "             105: [],\n",
       "             90: [],\n",
       "             103: [],\n",
       "             80: [],\n",
       "             102: [],\n",
       "             92: [],\n",
       "             101: [],\n",
       "             97: [],\n",
       "             99: [],\n",
       "             98: [],\n",
       "             96: [],\n",
       "             95: [],\n",
       "             94: [],\n",
       "             93: [],\n",
       "             91: [],\n",
       "             89: [],\n",
       "             88: [],\n",
       "             87: [],\n",
       "             86: [],\n",
       "             85: [],\n",
       "             84: [],\n",
       "             83: [],\n",
       "             82: [],\n",
       "             81: [],\n",
       "             159: [],\n",
       "             121: [],\n",
       "             158: [],\n",
       "             150: [],\n",
       "             157: [],\n",
       "             156: [],\n",
       "             155: [],\n",
       "             126: [],\n",
       "             154: [],\n",
       "             153: [],\n",
       "             148: [],\n",
       "             152: [],\n",
       "             130: [],\n",
       "             151: [],\n",
       "             149: [],\n",
       "             137: [],\n",
       "             147: [],\n",
       "             146: [],\n",
       "             145: [],\n",
       "             144: [],\n",
       "             125: [],\n",
       "             143: [],\n",
       "             142: [],\n",
       "             141: [],\n",
       "             140: [],\n",
       "             139: [],\n",
       "             138: [],\n",
       "             136: [],\n",
       "             135: [],\n",
       "             134: [],\n",
       "             124: [],\n",
       "             133: [],\n",
       "             132: [],\n",
       "             131: [],\n",
       "             127: [],\n",
       "             129: [],\n",
       "             128: [],\n",
       "             123: [],\n",
       "             120: [],\n",
       "             122: [],\n",
       "             199: [],\n",
       "             198: [],\n",
       "             197: [],\n",
       "             196: [],\n",
       "             195: [],\n",
       "             194: [],\n",
       "             193: [],\n",
       "             192: [],\n",
       "             191: [],\n",
       "             190: [],\n",
       "             189: [],\n",
       "             188: [],\n",
       "             165: [],\n",
       "             187: [],\n",
       "             186: [],\n",
       "             185: [],\n",
       "             184: [],\n",
       "             183: [],\n",
       "             182: [],\n",
       "             181: [],\n",
       "             180: [],\n",
       "             179: [],\n",
       "             178: [],\n",
       "             177: [],\n",
       "             176: [],\n",
       "             175: [],\n",
       "             174: [],\n",
       "             173: [],\n",
       "             172: [],\n",
       "             171: [],\n",
       "             170: [],\n",
       "             169: [],\n",
       "             168: [],\n",
       "             167: [],\n",
       "             166: [],\n",
       "             164: [],\n",
       "             163: [],\n",
       "             162: [],\n",
       "             161: [],\n",
       "             160: [],\n",
       "             239: [],\n",
       "             238: [],\n",
       "             237: [],\n",
       "             236: [],\n",
       "             235: [],\n",
       "             234: [],\n",
       "             233: [],\n",
       "             232: [],\n",
       "             231: [],\n",
       "             230: [],\n",
       "             229: [],\n",
       "             228: [],\n",
       "             227: [],\n",
       "             226: [],\n",
       "             225: [],\n",
       "             224: [],\n",
       "             223: [],\n",
       "             222: [],\n",
       "             221: [],\n",
       "             204: [],\n",
       "             220: [],\n",
       "             219: [],\n",
       "             218: [],\n",
       "             217: [],\n",
       "             216: [],\n",
       "             215: [],\n",
       "             214: [],\n",
       "             213: [],\n",
       "             212: [],\n",
       "             211: [],\n",
       "             210: [],\n",
       "             209: [],\n",
       "             208: [],\n",
       "             207: [],\n",
       "             206: [],\n",
       "             205: [],\n",
       "             203: [],\n",
       "             202: [],\n",
       "             201: [],\n",
       "             200: [],\n",
       "             279: [],\n",
       "             278: [],\n",
       "             277: [],\n",
       "             276: [],\n",
       "             253: [],\n",
       "             275: [],\n",
       "             247: [],\n",
       "             274: [],\n",
       "             273: [],\n",
       "             246: [],\n",
       "             272: [],\n",
       "             260: [],\n",
       "             271: [],\n",
       "             270: [],\n",
       "             269: [],\n",
       "             268: [],\n",
       "             267: [],\n",
       "             265: [],\n",
       "             266: [],\n",
       "             264: [],\n",
       "             263: [],\n",
       "             252: [],\n",
       "             262: [],\n",
       "             261: [],\n",
       "             242: [],\n",
       "             259: [],\n",
       "             258: [],\n",
       "             257: [],\n",
       "             256: [],\n",
       "             255: [],\n",
       "             254: [],\n",
       "             251: [],\n",
       "             250: [],\n",
       "             243: [],\n",
       "             249: [],\n",
       "             248: [],\n",
       "             245: [],\n",
       "             244: [],\n",
       "             241: [],\n",
       "             240: [],\n",
       "             319: [],\n",
       "             318: [],\n",
       "             317: [],\n",
       "             316: [],\n",
       "             315: [],\n",
       "             314: [],\n",
       "             313: [],\n",
       "             312: [],\n",
       "             311: [],\n",
       "             310: [],\n",
       "             309: [],\n",
       "             308: [],\n",
       "             307: [],\n",
       "             306: [],\n",
       "             305: [],\n",
       "             304: [],\n",
       "             303: [],\n",
       "             302: [],\n",
       "             301: [],\n",
       "             300: [],\n",
       "             299: [],\n",
       "             298: [],\n",
       "             297: [],\n",
       "             296: [],\n",
       "             295: [],\n",
       "             294: [],\n",
       "             293: [],\n",
       "             292: [],\n",
       "             291: [],\n",
       "             290: [],\n",
       "             289: [],\n",
       "             288: [],\n",
       "             287: [],\n",
       "             286: [],\n",
       "             285: [],\n",
       "             284: [],\n",
       "             283: [],\n",
       "             282: [],\n",
       "             281: [],\n",
       "             280: [],\n",
       "             359: [],\n",
       "             358: [],\n",
       "             348: [],\n",
       "             357: [],\n",
       "             356: [],\n",
       "             355: [],\n",
       "             354: [],\n",
       "             353: [],\n",
       "             352: [],\n",
       "             351: [],\n",
       "             335: [],\n",
       "             350: [],\n",
       "             349: [],\n",
       "             347: [],\n",
       "             346: [],\n",
       "             345: [],\n",
       "             344: [],\n",
       "             330: [],\n",
       "             343: [],\n",
       "             342: [],\n",
       "             341: [],\n",
       "             340: [],\n",
       "             339: [],\n",
       "             338: [],\n",
       "             337: [],\n",
       "             336: [],\n",
       "             334: [],\n",
       "             333: [],\n",
       "             332: [],\n",
       "             331: [],\n",
       "             329: [],\n",
       "             328: [],\n",
       "             327: [],\n",
       "             326: [],\n",
       "             325: [],\n",
       "             324: [],\n",
       "             323: [],\n",
       "             322: [],\n",
       "             321: [],\n",
       "             320: [],\n",
       "             399: [],\n",
       "             398: [],\n",
       "             397: [],\n",
       "             396: [],\n",
       "             395: [],\n",
       "             394: [],\n",
       "             385: [],\n",
       "             393: [],\n",
       "             392: [],\n",
       "             391: [],\n",
       "             390: [],\n",
       "             389: [],\n",
       "             388: [],\n",
       "             387: [],\n",
       "             386: [],\n",
       "             384: [],\n",
       "             383: [],\n",
       "             382: [],\n",
       "             381: [],\n",
       "             380: [],\n",
       "             379: [],\n",
       "             378: [],\n",
       "             377: [],\n",
       "             376: [],\n",
       "             375: [],\n",
       "             374: [],\n",
       "             373: [],\n",
       "             372: [],\n",
       "             371: [],\n",
       "             370: [],\n",
       "             369: [],\n",
       "             368: [],\n",
       "             363: [],\n",
       "             367: [],\n",
       "             366: [],\n",
       "             365: [],\n",
       "             364: [],\n",
       "             362: [],\n",
       "             361: [],\n",
       "             360: [],\n",
       "             439: [],\n",
       "             415: [],\n",
       "             438: [],\n",
       "             437: [],\n",
       "             436: [],\n",
       "             435: [],\n",
       "             434: [],\n",
       "             433: [],\n",
       "             432: [],\n",
       "             431: [],\n",
       "             430: [],\n",
       "             429: [],\n",
       "             428: [],\n",
       "             427: [],\n",
       "             426: [],\n",
       "             417: [],\n",
       "             425: [],\n",
       "             424: [],\n",
       "             423: [],\n",
       "             422: [],\n",
       "             421: [],\n",
       "             420: [],\n",
       "             400: [],\n",
       "             419: [],\n",
       "             418: [],\n",
       "             416: [],\n",
       "             414: [],\n",
       "             413: [],\n",
       "             412: [],\n",
       "             411: [],\n",
       "             410: [],\n",
       "             409: [],\n",
       "             408: [],\n",
       "             407: [],\n",
       "             406: [],\n",
       "             405: [],\n",
       "             404: [],\n",
       "             403: [],\n",
       "             402: [],\n",
       "             401: [],\n",
       "             479: [],\n",
       "             478: [],\n",
       "             477: [],\n",
       "             476: [],\n",
       "             475: [],\n",
       "             474: [],\n",
       "             473: [],\n",
       "             472: [],\n",
       "             471: [],\n",
       "             470: [],\n",
       "             469: [],\n",
       "             468: [],\n",
       "             467: [],\n",
       "             466: [],\n",
       "             465: [],\n",
       "             464: [],\n",
       "             463: [],\n",
       "             462: [],\n",
       "             461: [],\n",
       "             460: [],\n",
       "             459: [],\n",
       "             458: [],\n",
       "             457: [],\n",
       "             456: [],\n",
       "             455: [],\n",
       "             454: [],\n",
       "             453: [],\n",
       "             452: [],\n",
       "             451: [],\n",
       "             450: [],\n",
       "             449: [],\n",
       "             448: [],\n",
       "             447: [],\n",
       "             446: [],\n",
       "             445: [],\n",
       "             444: [],\n",
       "             443: [],\n",
       "             442: [],\n",
       "             441: [],\n",
       "             440: [],\n",
       "             519: [],\n",
       "             518: [],\n",
       "             517: [],\n",
       "             516: [],\n",
       "             515: [],\n",
       "             486: [],\n",
       "             514: [],\n",
       "             504: [],\n",
       "             513: [],\n",
       "             512: [],\n",
       "             511: [],\n",
       "             510: [],\n",
       "             509: [],\n",
       "             508: [],\n",
       "             507: [],\n",
       "             506: [],\n",
       "             505: [],\n",
       "             503: [],\n",
       "             502: [],\n",
       "             501: [],\n",
       "             500: [],\n",
       "             499: [],\n",
       "             498: [],\n",
       "             497: [],\n",
       "             496: [],\n",
       "             495: [],\n",
       "             494: [],\n",
       "             493: [],\n",
       "             492: [],\n",
       "             491: [],\n",
       "             490: [],\n",
       "             489: [],\n",
       "             488: [],\n",
       "             487: [],\n",
       "             485: [],\n",
       "             484: [],\n",
       "             483: [],\n",
       "             482: [],\n",
       "             481: [],\n",
       "             480: [],\n",
       "             559: [],\n",
       "             558: [],\n",
       "             557: [],\n",
       "             556: [],\n",
       "             555: [],\n",
       "             554: [],\n",
       "             553: [],\n",
       "             552: [],\n",
       "             533: [],\n",
       "             551: [],\n",
       "             550: [],\n",
       "             549: [],\n",
       "             548: [],\n",
       "             547: [],\n",
       "             546: [],\n",
       "             545: [],\n",
       "             544: [],\n",
       "             543: [],\n",
       "             542: [],\n",
       "             541: [],\n",
       "             540: [],\n",
       "             539: [],\n",
       "             538: [],\n",
       "             537: [],\n",
       "             536: [],\n",
       "             535: [],\n",
       "             534: [],\n",
       "             532: [],\n",
       "             531: [],\n",
       "             530: [],\n",
       "             529: [],\n",
       "             528: [],\n",
       "             527: [],\n",
       "             526: [],\n",
       "             525: [],\n",
       "             524: [],\n",
       "             523: [],\n",
       "             522: [],\n",
       "             521: [],\n",
       "             520: [],\n",
       "             599: [],\n",
       "             598: [],\n",
       "             597: [],\n",
       "             596: [],\n",
       "             595: [],\n",
       "             594: [],\n",
       "             593: [],\n",
       "             592: [],\n",
       "             591: [],\n",
       "             590: [],\n",
       "             589: [],\n",
       "             588: [],\n",
       "             587: [],\n",
       "             586: [],\n",
       "             585: [],\n",
       "             584: [],\n",
       "             583: [],\n",
       "             582: [],\n",
       "             581: [],\n",
       "             580: [],\n",
       "             579: [],\n",
       "             578: [],\n",
       "             577: [],\n",
       "             576: [],\n",
       "             575: [],\n",
       "             574: [],\n",
       "             573: [],\n",
       "             572: [],\n",
       "             571: [],\n",
       "             570: [],\n",
       "             569: [],\n",
       "             568: [],\n",
       "             567: [],\n",
       "             566: [],\n",
       "             565: [],\n",
       "             564: [],\n",
       "             563: [],\n",
       "             562: [],\n",
       "             561: [],\n",
       "             560: [],\n",
       "             639: [],\n",
       "             638: [],\n",
       "             624: [],\n",
       "             637: [],\n",
       "             636: [],\n",
       "             635: [],\n",
       "             634: [],\n",
       "             633: [],\n",
       "             632: [],\n",
       "             631: [],\n",
       "             630: [],\n",
       "             629: [],\n",
       "             628: [],\n",
       "             627: [],\n",
       "             626: [],\n",
       "             625: [],\n",
       "             623: [],\n",
       "             622: [],\n",
       "             621: [],\n",
       "             620: [],\n",
       "             619: [],\n",
       "             618: [],\n",
       "             617: [],\n",
       "             616: [],\n",
       "             615: [],\n",
       "             614: [],\n",
       "             613: [],\n",
       "             612: [],\n",
       "             611: [],\n",
       "             610: [],\n",
       "             609: [],\n",
       "             608: [],\n",
       "             607: [],\n",
       "             606: [],\n",
       "             605: [],\n",
       "             604: [],\n",
       "             603: [],\n",
       "             602: [],\n",
       "             601: [],\n",
       "             600: [],\n",
       "             679: [],\n",
       "             678: [],\n",
       "             677: [],\n",
       "             676: [],\n",
       "             675: [],\n",
       "             674: [],\n",
       "             673: [],\n",
       "             672: [],\n",
       "             671: [],\n",
       "             670: [],\n",
       "             669: [],\n",
       "             668: [],\n",
       "             667: [],\n",
       "             666: [],\n",
       "             665: [],\n",
       "             664: [],\n",
       "             663: [],\n",
       "             662: [],\n",
       "             661: [],\n",
       "             660: [],\n",
       "             659: [],\n",
       "             658: [],\n",
       "             657: [],\n",
       "             656: [],\n",
       "             655: [],\n",
       "             654: [],\n",
       "             653: [],\n",
       "             652: [],\n",
       "             651: [],\n",
       "             650: [],\n",
       "             649: [],\n",
       "             648: [],\n",
       "             647: [],\n",
       "             646: [],\n",
       "             645: [],\n",
       "             644: [],\n",
       "             643: [],\n",
       "             642: [],\n",
       "             641: [],\n",
       "             640: [],\n",
       "             703: [],\n",
       "             719: [],\n",
       "             718: [],\n",
       "             717: [],\n",
       "             716: [],\n",
       "             715: [],\n",
       "             714: [],\n",
       "             713: [],\n",
       "             712: [],\n",
       "             711: [],\n",
       "             710: [],\n",
       "             709: [],\n",
       "             708: [],\n",
       "             707: [],\n",
       "             706: [],\n",
       "             705: [],\n",
       "             704: [],\n",
       "             702: [],\n",
       "             701: [],\n",
       "             700: [],\n",
       "             699: [],\n",
       "             698: [],\n",
       "             697: [],\n",
       "             696: [],\n",
       "             695: [],\n",
       "             694: [],\n",
       "             693: [],\n",
       "             692: [],\n",
       "             691: [],\n",
       "             690: [],\n",
       "             689: [],\n",
       "             688: [],\n",
       "             687: [],\n",
       "             686: [],\n",
       "             685: [],\n",
       "             684: [],\n",
       "             683: [],\n",
       "             682: [],\n",
       "             681: [],\n",
       "             680: [],\n",
       "             759: [],\n",
       "             758: [],\n",
       "             757: [],\n",
       "             736: [],\n",
       "             756: [],\n",
       "             755: [],\n",
       "             754: [],\n",
       "             753: [],\n",
       "             752: [],\n",
       "             751: [],\n",
       "             750: [],\n",
       "             749: [],\n",
       "             748: [],\n",
       "             747: [],\n",
       "             746: [],\n",
       "             745: [],\n",
       "             744: [],\n",
       "             743: [],\n",
       "             742: [],\n",
       "             741: [],\n",
       "             740: [],\n",
       "             739: [],\n",
       "             738: [],\n",
       "             737: [],\n",
       "             735: [],\n",
       "             734: [],\n",
       "             733: [],\n",
       "             732: [],\n",
       "             731: [],\n",
       "             730: [],\n",
       "             729: [],\n",
       "             728: [],\n",
       "             727: [],\n",
       "             726: [],\n",
       "             725: [],\n",
       "             724: [],\n",
       "             723: [],\n",
       "             722: [],\n",
       "             721: [],\n",
       "             720: [],\n",
       "             799: [],\n",
       "             798: [],\n",
       "             797: [],\n",
       "             796: [],\n",
       "             795: [],\n",
       "             794: [],\n",
       "             793: [],\n",
       "             792: [],\n",
       "             791: [],\n",
       "             780: [],\n",
       "             790: [],\n",
       "             789: [],\n",
       "             788: [],\n",
       "             787: [],\n",
       "             786: [],\n",
       "             785: [],\n",
       "             768: [],\n",
       "             784: [],\n",
       "             783: [],\n",
       "             782: [],\n",
       "             781: [],\n",
       "             779: [],\n",
       "             778: [],\n",
       "             777: [],\n",
       "             776: [],\n",
       "             775: [],\n",
       "             774: [],\n",
       "             773: [],\n",
       "             772: [],\n",
       "             771: [],\n",
       "             770: [],\n",
       "             769: [],\n",
       "             767: [],\n",
       "             766: [],\n",
       "             765: [],\n",
       "             764: [],\n",
       "             763: [],\n",
       "             762: [],\n",
       "             761: [],\n",
       "             760: [],\n",
       "             839: [],\n",
       "             838: [],\n",
       "             837: [],\n",
       "             836: [],\n",
       "             835: [],\n",
       "             834: [],\n",
       "             833: [],\n",
       "             832: [],\n",
       "             831: [],\n",
       "             830: [],\n",
       "             829: [],\n",
       "             828: [],\n",
       "             827: [],\n",
       "             826: [],\n",
       "             825: [],\n",
       "             824: [],\n",
       "             823: [],\n",
       "             822: [],\n",
       "             821: [],\n",
       "             820: [],\n",
       "             819: [],\n",
       "             818: [],\n",
       "             817: [],\n",
       "             816: [],\n",
       "             815: [],\n",
       "             814: [],\n",
       "             813: [],\n",
       "             808: [],\n",
       "             812: [],\n",
       "             811: [],\n",
       "             810: [],\n",
       "             809: [],\n",
       "             807: [],\n",
       "             806: [],\n",
       "             805: [],\n",
       "             804: [],\n",
       "             803: [],\n",
       "             802: [],\n",
       "             801: [],\n",
       "             800: [],\n",
       "             879: [],\n",
       "             878: [],\n",
       "             877: [],\n",
       "             876: [],\n",
       "             875: [],\n",
       "             874: [],\n",
       "             873: [],\n",
       "             872: [],\n",
       "             871: [],\n",
       "             870: [],\n",
       "             869: [],\n",
       "             868: [],\n",
       "             867: [],\n",
       "             866: [],\n",
       "             865: [],\n",
       "             864: [],\n",
       "             863: [],\n",
       "             862: [],\n",
       "             861: [],\n",
       "             860: [],\n",
       "             859: [],\n",
       "             858: [],\n",
       "             857: [],\n",
       "             856: [],\n",
       "             855: [],\n",
       "             854: [],\n",
       "             853: [],\n",
       "             852: [],\n",
       "             851: [],\n",
       "             850: [],\n",
       "             849: [],\n",
       "             848: [],\n",
       "             847: [],\n",
       "             846: [],\n",
       "             845: [],\n",
       "             844: [],\n",
       "             843: [],\n",
       "             842: [],\n",
       "             840: [],\n",
       "             841: [],\n",
       "             919: [],\n",
       "             918: [],\n",
       "             917: [],\n",
       "             916: [],\n",
       "             915: [],\n",
       "             914: [],\n",
       "             913: [],\n",
       "             912: [],\n",
       "             911: [],\n",
       "             910: [],\n",
       "             909: [],\n",
       "             908: [],\n",
       "             907: [],\n",
       "             906: [],\n",
       "             905: [],\n",
       "             904: [],\n",
       "             903: [],\n",
       "             902: [],\n",
       "             901: [],\n",
       "             900: [],\n",
       "             899: [],\n",
       "             898: [],\n",
       "             897: [],\n",
       "             896: [],\n",
       "             895: [],\n",
       "             894: [],\n",
       "             893: [],\n",
       "             892: [],\n",
       "             891: [],\n",
       "             890: [],\n",
       "             889: [],\n",
       "             888: [],\n",
       "             887: [],\n",
       "             886: [],\n",
       "             885: [],\n",
       "             884: [],\n",
       "             883: [],\n",
       "             882: [],\n",
       "             881: [],\n",
       "             880: [],\n",
       "             947: [],\n",
       "             959: [],\n",
       "             953: [],\n",
       "             958: [],\n",
       "             957: [],\n",
       "             956: [],\n",
       "             955: [],\n",
       "             954: [],\n",
       "             952: [],\n",
       "             951: [],\n",
       "             950: [],\n",
       "             949: [],\n",
       "             948: [],\n",
       "             946: [],\n",
       "             945: [],\n",
       "             944: [],\n",
       "             943: [],\n",
       "             942: [],\n",
       "             941: [],\n",
       "             940: [],\n",
       "             939: [],\n",
       "             938: [],\n",
       "             937: [],\n",
       "             936: [],\n",
       "             935: [],\n",
       "             934: [],\n",
       "             933: [],\n",
       "             932: [],\n",
       "             931: [],\n",
       "             930: [],\n",
       "             929: [],\n",
       "             928: [],\n",
       "             927: [],\n",
       "             926: [],\n",
       "             925: [],\n",
       "             924: [],\n",
       "             923: [],\n",
       "             922: [],\n",
       "             921: [],\n",
       "             920: [],\n",
       "             ...})"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcorpus.selected_book_ids_by_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.wrappers.dtmmodel:serializing temporary corpus to /var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train-mult.dat\n",
      "INFO:gensim.corpora.bleicorpus:no word id mapping provided; initializing from corpus\n",
      "INFO:gensim.corpora.bleicorpus:storing corpus in Blei's LDA-C format into /var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train-mult.dat\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'wb', 'uri': '/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train-mult.dat'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'wb', 'fileobj': <_io.BufferedWriter name='/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train-mult.dat'>}\n",
      "INFO:gensim.corpora.bleicorpus:saving vocabulary of 34946 words to /var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train-mult.dat.vocab\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'wb', 'uri': '/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train-mult.dat.vocab'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'wb', 'fileobj': <_io.BufferedWriter name='/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train-mult.dat.vocab'>}\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'wb', 'uri': '/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train-seq.dat'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'wb', 'fileobj': <_io.BufferedWriter name='/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train-seq.dat'>}\n",
      "INFO:gensim.models.wrappers.dtmmodel:training DTM with args --ntopics=5 --model=dtm  --mode=fit --initialize_lda=true --corpus_prefix=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train --outname=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train_out --alpha=0.01 --lda_max_em_iter=10 --lda_sequence_min_iter=6  --lda_sequence_max_iter=20 --top_chain_var=0.005 --rng_seed=0 \n",
      "INFO:gensim.models.wrappers.dtmmodel:Running command ['/Users/jmc/src/dtm/dtm_release/dtm/main', '--ntopics=5', '--model=dtm', '--mode=fit', '--initialize_lda=true', '--corpus_prefix=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train', '--outname=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train_out', '--alpha=0.01', '--lda_max_em_iter=10', '--lda_sequence_min_iter=6', '--lda_sequence_max_iter=20', '--top_chain_var=0.005', '--rng_seed=0']\n",
      "DEBUG:gensim.utils:COMMAND: () {'args': ['/Users/jmc/src/dtm/dtm_release/dtm/main', '--ntopics=5', '--model=dtm', '--mode=fit', '--initialize_lda=true', '--corpus_prefix=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train', '--outname=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/19274_train_out', '--alpha=0.01', '--lda_max_em_iter=10', '--lda_sequence_min_iter=6', '--lda_sequence_max_iter=20', '--top_chain_var=0.005', '--rng_seed=0'], 'stderr': -1}\n"
     ]
    }
   ],
   "source": [
    "# Unused DTM params: alpha, lda_{min,max}_em_iter, lda_sequence_max_iter, top_chain_var\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "gmodel = DtmModel(DTM_PATH\n",
    "                  , gcorpus\n",
    "                  , gcorpus.get_time_seq()\n",
    "                  , num_topics=5\n",
    "                  , id2word=gcorpus.dictionary\n",
    "                  , initialize_lda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Topic 0 0.138458\n",
      "Distribution of Topic 1 0.054126\n",
      "Distribution of Topic 2 0.065588\n",
      "Distribution of Topic 3 0.688575\n",
      "Distribution of Topic 4 0.053254\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, num_topics):\n",
    "    print (\"Distribution of Topic %d %f\" % (i, gmodel.gamma_[doc_number, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.004709813297933354, 'library'), (0.0030859186326109753, 'committee'), (0.0025127749895826833, 'wilson'), (0.0024379646463592013, 'college'), (0.002434622884332607, 'washington'), (0.0018991987382760123, 'today'), (0.0018580589476396114, 'libraries'), (0.0018556990426500722, 'national'), (0.0017765834621545381, 'cabinet'), (0.0016797862538621923, 'vol')]\n",
      "\n",
      "[(0.013533164612376476, 'germany'), (0.004565220325777083, 'allies'), (0.0036153642431063365, 'trenches'), (0.002240150072473574, 'russians'), (0.0021046158194542074, 'count'), (0.002092974286787563, 'italian'), (0.0020876886599896006, 'steamer'), (0.001727233186679671, '_from'), (0.0016668122493052834, 'natives'), (0.0016150071120506861, 'coast')]\n",
      "\n",
      "[(0.0067748156055602105, 'german'), (0.0066786960792193885, 'attack'), (0.003531100981064933, 'shelter'), (0.002722614545507283, 'supplies'), (0.0024242888029083146, 'emergency'), (0.0021613581423069, 'local'), (0.0021434309750827576, 'warning'), (0.0020908846526805306, 'guns'), (0.001832160601596661, 'available'), (0.001762964459136354, 'fighting')]\n",
      "\n",
      "[(0.002295814574532267, 'italy'), (0.002227724912321257, 'science'), (0.0016829496014288251, 'music'), (0.0015060174148172724, 'stories'), (0.0014441889553848414, 'troops'), (0.001432258816341596, 'guns'), (0.0013910380816809366, 'professor'), (0.0013442468974352113, 'sand'), (0.0012672617190342592, 'captured'), (0.0012095968106494816, 'stones')]\n",
      "\n",
      "[(0.028718893398620726, 'german'), (0.005704472804022545, 'germans'), (0.005088916186443061, 'joan'), (0.005066605487415178, 'bryan'), (0.004518254589977896, 'girl'), (0.004358691818380432, 'fallout'), (0.004021271360526131, 'russian'), (0.002943597222156228, 'submarine'), (0.0026671715046340805, 'mrs'), (0.0024862396925750966, 'tha')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topicid in [0,1,2,3,4]: # 1900s\n",
    "    print(gmodel.show_topic(topicid=topicid, time=28, topn=10))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Deserted Woman', 'The Collection of Antiquities']"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[book['title'] for book in gcorpus.books if book['id'] in [1405, 1729]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'author': 'Honore de Balzac',\n",
       "  'content_lines': None,\n",
       "  'error': '',\n",
       "  'id': 1729,\n",
       "  'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/7/2/1729/1729.zip',\n",
       "  'title': 'The Deserted Woman',\n",
       "  'year': '1999'}]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[book for book in gcorpus.books if book['id'] == 1729]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc #0=Book ID #15835\n",
      "\t{'id': 15835, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/5/8/3/15835/15835.zip', 'author': 'William Lilly', 'title': \"William Lilly's History of His Life and Times\", 'year': '1602', 'content_lines': None, 'error': ''}\n",
      "Doc #1=Book ID #48594\n",
      "\t{'id': 48594, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/8/5/9/48594/48594-0.zip', 'author': 'Ernest Stuart Bates', 'title': 'Touring in 1600', 'year': '1600', 'content_lines': None, 'error': ''}\n",
      "Doc #2=Book ID #12259\n",
      "\t{'id': 12259, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/2/2/5/12259/12259.zip', 'author': 'Daniel Defoe', 'title': 'Memoirs of a Cavalier', 'year': '1632', 'content_lines': None, 'error': ''}\n",
      "Doc #3=Book ID #38417\n",
      "\t{'id': 38417, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/3/8/4/1/38417/38417.zip', 'author': 'William W. Wheildon', 'title': 'Curiosities of History', 'year': '1630', 'content_lines': None, 'error': ''}\n",
      "Doc #4=Book ID #47462\n",
      "\t{'id': 47462, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/7/4/6/47462/47462-0.zip', 'author': 'William Habington', 'title': 'Castara', 'year': '1640', 'content_lines': None, 'error': ''}\n",
      "Doc #5=Book ID #47462\n",
      "\t{'id': 47462, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/7/4/6/47462/47462-0.zip', 'author': 'William Habington', 'title': 'Castara', 'year': '1640', 'content_lines': None, 'error': ''}\n",
      "Doc #6=Book ID #9198\n",
      "\t{'id': 9198, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/9/1/9/9198/9198.zip', 'author': 'Isaak Walton', 'title': 'The Complete Angler, 1653', 'year': '1653', 'content_lines': None, 'error': ''}\n",
      "Doc #7=Book ID #9198\n",
      "\t{'id': 9198, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/9/1/9/9198/9198.zip', 'author': 'Isaak Walton', 'title': 'The Complete Angler, 1653', 'year': '1653', 'content_lines': None, 'error': ''}\n",
      "Doc #8=Book ID #4170\n",
      "\t{'id': 4170, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/1/7/4170/4170.zip', 'author': 'Samuel Pepys', 'title': 'Diary of Samuel Pepys, December 1666', 'year': '1666', 'content_lines': None, 'error': ''}\n",
      "Doc #9=Book ID #4168\n",
      "\t{'id': 4168, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/1/6/4168/4168.zip', 'author': 'Samuel Pepys', 'title': 'Diary of Samuel Pepys, October 1666', 'year': '1666', 'content_lines': None, 'error': ''}\n",
      "Doc #10=Book ID #28010\n",
      "\t{'id': 28010, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/8/0/1/28010/28010.zip', 'author': 'Thomas Jefferson Wertenbaker', 'title': \"Bacon's Rebellion, 1676\", 'year': '1676', 'content_lines': None, 'error': ''}\n",
      "Doc #11=Book ID #28010\n",
      "\t{'id': 28010, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/8/0/1/28010/28010.zip', 'author': 'Thomas Jefferson Wertenbaker', 'title': \"Bacon's Rebellion, 1676\", 'year': '1676', 'content_lines': None, 'error': ''}\n",
      "Doc #12=Book ID #16335\n",
      "\t{'id': 16335, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/6/3/3/16335/16335.zip', 'author': \"Thomas D'Urfey and Bossuet\", 'title': 'Essays on the Stage', 'year': '1689', 'content_lines': None, 'error': ''}\n",
      "Doc #13=Book ID #16335\n",
      "\t{'id': 16335, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/6/3/3/16335/16335.zip', 'author': \"Thomas D'Urfey and Bossuet\", 'title': 'Essays on the Stage', 'year': '1689', 'content_lines': None, 'error': ''}\n",
      "Doc #14=Book ID #13274\n",
      "\t{'id': 13274, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/3/2/7/13274/13274.zip', 'author': 'John Mason', 'title': 'A Little Catechism, 1692', 'year': '1692', 'content_lines': None, 'error': ''}\n",
      "Doc #15=Book ID #13274\n",
      "\t{'id': 13274, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/3/2/7/13274/13274.zip', 'author': 'John Mason', 'title': 'A Little Catechism, 1692', 'year': '1692', 'content_lines': None, 'error': ''}\n",
      "Doc #16=Book ID #36587\n",
      "\t{'id': 36587, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/3/6/5/8/36587/36587.zip', 'author': 'Daniel Defoe', 'title': 'A True Relation of the Apparition of one Mrs. Veal', 'year': '1705', 'content_lines': None, 'error': ''}\n",
      "Doc #17=Book ID #36587\n",
      "\t{'id': 36587, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/3/6/5/8/36587/36587.zip', 'author': 'Daniel Defoe', 'title': 'A True Relation of the Apparition of one Mrs. Veal', 'year': '1705', 'content_lines': None, 'error': ''}\n",
      "Doc #18=Book ID #12381\n",
      "\t{'id': 12381, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/2/3/8/12381/12381.zip', 'author': 'The Reformed Presbytery', 'title': 'The Auchensaugh Renovation of the National Covenant and', 'year': '1712', 'content_lines': None, 'error': ''}\n",
      "Doc #19=Book ID #12381\n",
      "\t{'id': 12381, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/2/3/8/12381/12381.zip', 'author': 'The Reformed Presbytery', 'title': 'The Auchensaugh Renovation of the National Covenant and', 'year': '1712', 'content_lines': None, 'error': ''}\n",
      "Doc #20=Book ID #31673\n",
      "\t{'id': 31673, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/3/1/6/7/31673/31673.zip', 'author': 'Howard Pyle', 'title': 'The Rose of Paradise', 'year': '1720', 'content_lines': None, 'error': ''}\n",
      "Doc #21=Book ID #16299\n",
      "\t{'id': 16299, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/6/2/9/16299/16299.zip', 'author': 'Henry Gally', 'title': 'A Critical Essay on Characteristic-Writings', 'year': '1725', 'content_lines': None, 'error': ''}\n",
      "Doc #22=Book ID #2108\n",
      "\t{'id': 2108, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/1/0/2108/2108.zip', 'author': 'Thomas Carlyle', 'title': 'History Of Friedrich II. of Prussia, Vol. VIII. (of XXI.)', 'year': '1730', 'content_lines': None, 'error': ''}\n",
      "Doc #23=Book ID #2822\n",
      "\t{'id': 2822, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/8/2/2822/2822-0.zip', 'author': 'Don Manoel Gonzales', 'title': 'London in 1731', 'year': '1731', 'content_lines': None, 'error': ''}\n",
      "Doc #24=Book ID #18635\n",
      "\t{'id': 18635, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/8/6/3/18635/18635.zip', 'author': 'Various', 'title': 'The Treaty Held with the Indians of the Six Nations at Philadelphia, in July 1742', 'year': '1742', 'content_lines': None, 'error': ''}\n",
      "Doc #25=Book ID #2116\n",
      "\t{'id': 2116, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/1/1/2116/2116.zip', 'author': 'Thomas Carlyle', 'title': 'History of Friedrich II. of Prussia, Vol. XVI. (of XXI.)', 'year': '1746', 'content_lines': None, 'error': ''}\n",
      "Doc #26=Book ID #3355\n",
      "\t{'id': 3355, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/3/3/5/3355/3355.zip', 'author': 'The Earl of Chesterfield', 'title': 'Letters to His Son, 1751', 'year': '1751', 'content_lines': None, 'error': ''}\n",
      "Doc #27=Book ID #2119\n",
      "\t{'id': 2119, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/1/1/2119/2119.zip', 'author': 'Thomas Carlyle', 'title': 'History of Friedrich II. of Prussia, Vol. XIX. (of XXI.)', 'year': '1759', 'content_lines': None, 'error': ''}\n",
      "Doc #28=Book ID #30099\n",
      "\t{'id': 30099, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/3/0/0/9/30099/30099.zip', 'author': 'John Hill', 'title': 'Hypochondriasis', 'year': '1766', 'content_lines': None, 'error': ''}\n",
      "Doc #29=Book ID #16747\n",
      "\t{'id': 16747, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/6/7/4/16747/16747.zip', 'author': 'George M. Wrong', 'title': 'A Canadian Manor and Its Seigneurs', 'year': '1761', 'content_lines': None, 'error': ''}\n",
      "Doc #30=Book ID #14611\n",
      "\t{'id': 14611, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/4/6/1/14611/14611.zip', 'author': 'Robert Kerr', 'title': 'A General History and Collection of Voyages and Travels, Vol. 15 (of 18)', 'year': '1772', 'content_lines': None, 'error': ''}\n",
      "Doc #31=Book ID #49742\n",
      "\t{'id': 49742, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/9/7/4/49742/49742-0.zip', 'author': 'Frank Warren Coburn', 'title': 'The Battle of April 19, 1775', 'year': '1775', 'content_lines': None, 'error': ''}\n",
      "Doc #32=Book ID #45757\n",
      "\t{'id': 45757, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/5/7/5/45757/45757.zip', 'author': 'Various', 'title': 'A Source Book in American History to 1787', 'year': '1787', 'content_lines': None, 'error': ''}\n",
      "Doc #33=Book ID #22487\n",
      "\t{'id': 22487, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/2/4/8/22487/22487.zip', 'author': 'Lucinda Lee Orr', 'title': 'Journal of a Young Lady of Virginia, 1782', 'year': '1782', 'content_lines': None, 'error': ''}\n",
      "Doc #34=Book ID #8639\n",
      "\t{'id': 8639, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/8/6/3/8639/8639.zip', 'author': 'Robert Southey', 'title': 'Poems, 1799', 'year': '1799', 'content_lines': None, 'error': ''}\n",
      "Doc #35=Book ID #41144\n",
      "\t{'id': 41144, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/1/1/4/41144/41144-0.zip', 'author': 'M. E. James', 'title': 'The Fishguard Invasion by the French in 1797', 'year': '1797', 'content_lines': None, 'error': ''}\n",
      "Doc #36=Book ID #11866\n",
      "\t{'id': 11866, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/1/8/6/11866/11866.zip', 'author': 'Daniel Defoe', 'title': 'The Life and Most Surprising Adventures of Robinson Crusoe, of', 'year': '1801', 'content_lines': None, 'error': ''}\n",
      "Doc #37=Book ID #44408\n",
      "\t{'id': 44408, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/4/4/0/44408/44408.zip', 'author': 'Arthur Johnston', 'title': 'Narrative of the Operations of a Detachment in an Expedition to Candy, in the Island of Ceylon, in the Year 1804', 'year': '1804', 'content_lines': None, 'error': ''}\n",
      "Doc #38=Book ID #11203\n",
      "\t{'id': 11203, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/1/2/0/11203/11203.zip', 'author': 'Phillip Parker King', 'title': 'Narrative of a Survey of the Intertropical and Western Coasts of Australia', 'year': '1818', 'content_lines': None, 'error': ''}\n",
      "Doc #39=Book ID #44281\n",
      "\t{'id': 44281, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/4/2/8/44281/44281.zip', 'author': 'William Dunlop', 'title': 'Recollections of the War of 1812', 'year': '1812', 'content_lines': None, 'error': ''}\n",
      "Doc #40=Book ID #42482\n",
      "\t{'id': 42482, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/2/4/8/42482/42482.zip', 'author': 'George Thomas Love', 'title': \"A Five Years' Residence in Buenos Ayres\", 'year': '1820', 'content_lines': None, 'error': ''}\n",
      "Doc #41=Book ID #11460\n",
      "\t{'id': 11460, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/1/4/6/11460/11460.zip', 'author': 'Various', 'title': 'The Mirror of Literature, Amusement, and Instruction', 'year': '1829', 'content_lines': None, 'error': ''}\n",
      "Doc #42=Book ID #43540\n",
      "\t{'id': 43540, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/3/5/4/43540/43540.zip', 'author': 'J. D. Paxton', 'title': 'Letters from Palestine', 'year': '1836', 'content_lines': None, 'error': ''}\n",
      "Doc #43=Book ID #11903\n",
      "\t{'id': 11903, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/1/9/0/11903/11903.zip', 'author': 'Various', 'title': 'The Mirror of Literature, Amusement, and Instruction, Vol. 20,', 'year': '1832', 'content_lines': None, 'error': ''}\n",
      "Doc #44=Book ID #11454\n",
      "\t{'id': 11454, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/1/4/5/11454/11454.zip', 'author': 'Joseph Sturge', 'title': 'A Visit To The United States In 1841', 'year': '1841', 'content_lines': None, 'error': ''}\n",
      "Doc #45=Book ID #25633\n",
      "\t{'id': 25633, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/5/6/3/25633/25633.zip', 'author': 'Various', 'title': \"Blackwood's Edinburgh Magazine - Volume 62, No. 384, October 1847\", 'year': '1847', 'content_lines': None, 'error': ''}\n",
      "Doc #46=Book ID #37516\n",
      "\t{'id': 37516, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/3/7/5/1/37516/37516.zip', 'author': 'Various', 'title': 'Notes and Queries, Vol. III, Number 87, June 28, 1851', 'year': '1851', 'content_lines': None, 'error': ''}\n",
      "Doc #47=Book ID #36124\n",
      "\t{'id': 36124, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/3/6/1/2/36124/36124.zip', 'author': 'Various', 'title': 'The International Monthly, Volume 4, No. 1, August, 1851', 'year': '1851', 'content_lines': None, 'error': ''}\n",
      "Doc #48=Book ID #20647\n",
      "\t{'id': 20647, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/0/6/4/20647/20647.zip', 'author': 'Various', 'title': 'The Continental Monthly, Vol. 2, No 3,  September, 1862', 'year': '1862', 'content_lines': None, 'error': ''}\n",
      "Doc #49=Book ID #15819\n",
      "\t{'id': 15819, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/5/8/1/15819/15819.zip', 'author': 'Various', 'title': 'The Atlantic Monthly, Vol. 13, No. 76, February, 1864', 'year': '1864', 'content_lines': None, 'error': ''}\n",
      "Doc #50=Book ID #10014\n",
      "\t{'id': 10014, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/0/0/1/10014/10014.zip', 'author': 'Various', 'title': 'Punchinello, Vol. 1, No. 18, July 30, 1870', 'year': '1870', 'content_lines': None, 'error': ''}\n",
      "Doc #51=Book ID #25725\n",
      "\t{'id': 25725, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/5/7/2/25725/25725.zip', 'author': 'Frances Hodgson Burnett', 'title': \"That Lass O' Lowrie's\", 'year': '1877', 'content_lines': None, 'error': ''}\n",
      "Doc #52=Book ID #29134\n",
      "\t{'id': 29134, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/9/1/3/29134/29134.zip', 'author': 'Various', 'title': \"Harper's Young People, September 7, 1880\", 'year': '1880', 'content_lines': None, 'error': ''}\n",
      "Doc #53=Book ID #15924\n",
      "\t{'id': 15924, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/5/9/2/15924/15924.zip', 'author': 'Various', 'title': 'Bay State Monthly, Volume I, No. 2, February, 1884', 'year': '1884', 'content_lines': None, 'error': ''}\n",
      "Doc #54=Book ID #12905\n",
      "\t{'id': 12905, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/2/9/0/12905/12905.zip', 'author': 'Various', 'title': 'Punch, Or The London Charivari, Vol. 99., December 13, 1890', 'year': '1890', 'content_lines': None, 'error': ''}\n",
      "Doc #55=Book ID #32976\n",
      "\t{'id': 32976, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/3/2/9/7/32976/32976.zip', 'author': 'Various', 'title': \"Harper's Round Table, May 28, 1895\", 'year': '1895', 'content_lines': None, 'error': ''}\n",
      "Doc #56=Book ID #25107\n",
      "\t{'id': 25107, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/5/1/0/25107/25107.zip', 'author': 'Louis Becke', 'title': 'Sarreo', 'year': '1901', 'content_lines': None, 'error': ''}\n",
      "Doc #57=Book ID #23411\n",
      "\t{'id': 23411, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/3/4/1/23411/23411.zip', 'author': 'Robert Hichens', 'title': \"Smain; and Safti's Summer Day\", 'year': '1905', 'content_lines': None, 'error': ''}\n",
      "Doc #58=Book ID #26377\n",
      "\t{'id': 26377, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/6/3/7/26377/26377.zip', 'author': 'Various', 'title': 'New York Times Current History; The European War, Vol 2, No. 4, July, 1915', 'year': '1915', 'content_lines': None, 'error': ''}\n",
      "Doc #59=Book ID #28470\n",
      "\t{'id': 28470, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/8/4/7/28470/28470.zip', 'author': 'Various', 'title': 'Punch, or the London Charivari, Vol. 147, November 4, 1914', 'year': '1914', 'content_lines': None, 'error': ''}\n",
      "Doc #60=Book ID #20779\n",
      "\t{'id': 20779, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/0/7/7/20779/20779.zip', 'author': 'Various', 'title': 'Punch, or the London Charivari, Volume 159, October 27, 1920', 'year': '1920', 'content_lines': None, 'error': ''}\n",
      "Doc #61=Book ID #16684\n",
      "\t{'id': 16684, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/6/6/8/16684/16684.zip', 'author': 'Various', 'title': 'Punch, or the London Charivari, Vol. 159, July 7th, 1920', 'year': '1920', 'content_lines': None, 'error': ''}\n",
      "Doc #62=Book ID #46222\n",
      "\t{'id': 46222, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/6/2/2/46222/46222.zip', 'author': 'Various', 'title': 'The Fantasy Fan September 1933', 'year': '1933', 'content_lines': None, 'error': ''}\n",
      "Doc #63=Book ID #41622\n",
      "\t{'id': 41622, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/1/6/2/41622/41622.zip', 'author': 'Ray Bradbury', 'title': 'Futuria Fantasia, Summer 1939', 'year': '1939', 'content_lines': None, 'error': ''}\n",
      "Doc #64=Book ID #41651\n",
      "\t{'id': 41651, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/1/6/5/41651/41651.zip', 'author': 'Various', 'title': 'Futuria Fantasia, Spring 1940', 'year': '1940', 'content_lines': None, 'error': ''}\n",
      "Doc #65=Book ID #45185\n",
      "\t{'id': 45185, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/5/1/8/45185/45185.zip', 'author': 'Charles Lee Lewis', 'title': 'Burritt College Centennial Celebration', 'year': '1948', 'content_lines': None, 'error': ''}\n",
      "Doc #66=Book ID #25034\n",
      "\t{'id': 25034, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/5/0/3/25034/25034.zip', 'author': 'J. O. Wilson and General Assembly Library (New Zealand)', 'title': 'Report of the Chief Librarian', 'year': '1958', 'content_lines': None, 'error': ''}\n",
      "Doc #67=Book ID #19780\n",
      "\t{'id': 19780, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/9/7/8/19780/19780.zip', 'author': 'G. T. Alley and National Library Service (New Zealand)', 'title': 'Report of the National Library Service for the Year Ended 31 March 1958', 'year': '1958', 'content_lines': None, 'error': ''}\n",
      "Doc #68=Book ID #15158\n",
      "\t{'id': 15158, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/5/1/5/15158/15158.zip', 'author': 'Department of Defense', 'title': 'In Time Of Emergency', 'year': '1968', 'content_lines': None, 'error': ''}\n",
      "Doc #69=Book ID #15158\n",
      "\t{'id': 15158, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/5/1/5/15158/15158.zip', 'author': 'Department of Defense', 'title': 'In Time Of Emergency', 'year': '1968', 'content_lines': None, 'error': ''}\n",
      "Doc #70=Book ID #30557\n",
      "\t{'id': 30557, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/3/0/5/5/30557/30557.zip', 'author': 'Anonymous', 'title': 'The Long Island Library Resources Council (LILRC) Interlibrary Loan Manual: January, 1976', 'year': '1976', 'content_lines': None, 'error': ''}\n",
      "Doc #71=Book ID #5\n",
      "\t{'id': 5, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/0/5/5.zip', 'author': ' Founding Fathers', 'title': \"The United States' Constitution\", 'year': '1975', 'content_lines': None, 'error': ''}\n",
      "Doc #72=Book ID #4290\n",
      "\t{'id': 4290, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/2/9/4290/4290.zip', 'author': 'Ralph Centennius', 'title': 'The Dominion in 1983', 'year': '1983', 'content_lines': None, 'error': ''}\n",
      "Doc #73=Book ID #4290\n",
      "\t{'id': 4290, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/4/2/9/4290/4290.zip', 'author': 'Ralph Centennius', 'title': 'The Dominion in 1983', 'year': '1983', 'content_lines': None, 'error': ''}\n",
      "Doc #74=Book ID #1405\n",
      "\t{'id': 1405, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/4/0/1405/1405.zip', 'author': 'Honore de Balzac', 'title': 'The Collection of Antiquities', 'year': '1998', 'content_lines': None, 'error': ''}\n",
      "Doc #75=Book ID #1729\n",
      "\t{'id': 1729, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/1/7/2/1729/1729.zip', 'author': 'Honore de Balzac', 'title': 'The Deserted Woman', 'year': '1999', 'content_lines': None, 'error': ''}\n",
      "Doc #76=Book ID #21899\n",
      "\t{'id': 21899, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/2/1/8/9/21899/21899.zip', 'author': 'Frederick Cornell', 'title': 'A Rip Van Winkle Of The Kalahari', 'year': '2007', 'content_lines': None, 'error': ''}\n",
      "Doc #77=Book ID #3871\n",
      "\t{'id': 3871, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/3/8/7/3871/3871.zip', 'author': 'Duc de Saint-Simon', 'title': 'The Memoirs of Louis XIV., Volume 12', 'year': '2004', 'content_lines': None, 'error': ''}\n",
      "Doc #78=Book ID #34230\n",
      "\t{'id': 34230, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/3/4/2/3/34230/34230.zip', 'author': 'S. R. Crockett', 'title': 'Sweethearts at Home', 'year': '2010', 'content_lines': None, 'error': ''}\n",
      "Doc #79=Book ID #32331\n",
      "\t{'id': 32331, 'path': '/Users/jmc/git/jaycoskey/Coskey_Metis/projects/Project4/data/gutenberg_books_en/aleph.gutenberg.org/3/2/3/3/32331/32331.zip', 'author': 'Robert Sydney Bowen', 'title': 'Dave Dawson at Casablanca', 'year': '2010', 'content_lines': None, 'error': ''}\n"
     ]
    }
   ],
   "source": [
    "doc_num = 0\n",
    "for decade in gcorpus.decades:\n",
    "    for id in gcorpus.selected_book_ids_by_decade[decade]:\n",
    "        book = [book for book in gcorpus.books if book['id'] == id][0]\n",
    "        print(f'Doc #{doc_num}=Book ID #{id}')\n",
    "        print(f'\\t{book}')\n",
    "        doc_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Topic 0 0.113581\n",
      "Distribution of Topic 1 0.651897\n",
      "Distribution of Topic 2 0.043261\n",
      "Distribution of Topic 3 0.099869\n",
      "Distribution of Topic 4 0.091392\n"
     ]
    }
   ],
   "source": [
    "doc_number = 74\n",
    "num_topics = 5\n",
    "\n",
    "for k in range(0, num_topics):\n",
    "    print (\"Distribution of Topic %d %f\" % (k, gmodel.gamma_[doc_number, k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.matutils import hellinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_doc_num=74; dist=0.09426715845723534; min_vec_other=[0.11358060316904314, 0.6518968277835198, 0.04326092786677336, 0.09986923687216961, 0.0913924043084941]\n"
     ]
    }
   ],
   "source": [
    "# vec_primary = [0.071460, 0.044956, 0.068991, 0.058845, 0.755748] # sweethearts_at_home\n",
    "vec_primary = [0.059242, 0.733993, 0.022367, 0.119562, 0.064835]\n",
    "min_dist = 100\n",
    "min_doc_num = 100\n",
    "min_vec_other = None\n",
    "for doc_num in range(0, 80):\n",
    "    if doc_num == 75:\n",
    "        continue\n",
    "    vec_other = [ gmodel.gamma_[doc_num, 0]\n",
    "               , gmodel.gamma_[doc_num, 1]\n",
    "               , gmodel.gamma_[doc_num, 2]\n",
    "               , gmodel.gamma_[doc_num, 3]\n",
    "               , gmodel.gamma_[doc_num, 4]\n",
    "              ]\n",
    "    dist = hellinger(vec_primary, vec_other)\n",
    "    if dist < min_dist:\n",
    "        min_dist = dist\n",
    "        min_doc_num = doc_num\n",
    "        min_vec_other = vec_other\n",
    "\n",
    "print (f\"Min_doc_num={min_doc_num}; dist={min_dist}; min_vec_other={min_vec_other}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid_book_ids = []\n",
    "book_errors = {}\n",
    "for book_id_num, book_id in enumerate(get_book_ids(base_dir=GUTENBERG_DOWNLOAD_DIR)):\n",
    "    book_path_info = get_book_path_info(book_id, base_dir=GUTENBERG_DOWNLOAD_DIR)\n",
    "    if not book_path_info[0]:\n",
    "        print(f'Error with book #{book_id}: {book_path_info[1]}')\n",
    "        continue\n",
    "    book_path = book_path_info[0]\n",
    "    book = get_book_from_path(book_id, book_path)\n",
    "    if len(book['error']) == 0:\n",
    "        valid_book_ids.append(book_id)\n",
    "    else:\n",
    "        book_errors[book_id] = book['error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(valid_book_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open('valid_book_ids.txt', 'w') as f:\n",
    "    for id in sorted(valid_book_ids):\n",
    "        f.write(str(id) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "book_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles: ['Hacker Crackdown', 'United States Declaration of Independence', 'Helen of Troy and Other Poems', 'The Adventures of Pinocchio', 'Notes from the Underground', 'The Old Curiosity Shop', 'A Sentimental Journey through France and Italy', 'The Happy Prince']\n",
      "Years: ['2012', '2015', '2008', '2006', '2008', '2008', '2015', '2015']\n"
     ]
    }
   ],
   "source": [
    "ldamodel = test_lda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Topic Modeling (DTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample data from the dtmmodel documentation\n",
    "test_documents = [[u'senior', u'studios', u'studios', u'studios', u'creators', u'award'\n",
    "              , u'mobile', u'currently', u'challenges', u'senior', u'summary'\n",
    "              , u'senior', u'motivated', u'creative', u'senior', u'performs'\n",
    "              , u'engineering', u'tasks', u'infrastructure', u'focusing', u'primarily'\n",
    "              , u'programming', u'interaction', u'designers', u'engineers'\n",
    "              , u'leadership', u'teams', u'teams', u'crews', u'responsibilities'\n",
    "              , u'engineering', u'quality', u'functional', u'functional', u'teams'\n",
    "              , u'organizing', u'prioritizing', u'technical', u'decisions'\n",
    "              , u'engineering', u'participates', u'participates', u'reviews'\n",
    "              , u'participates', u'hiring', u'conducting', u'interviews'\n",
    "              , u'feedback', u'departments', u'define', u'focusing', u'engineering'\n",
    "              , u'teams', u'crews', u'facilitate', u'engineering', u'departments'\n",
    "              , u'deadlines', u'milestones', u'typically', u'spends', u'designing'\n",
    "              , u'developing', u'updating', u'bugs', u'mentoring', u'engineers'\n",
    "              , u'define', u'schedules', u'milestones', u'participating', u'reviews'\n",
    "              , u'interviews', u'sized', u'teams', u'interacts', u'disciplines'\n",
    "              , u'knowledge', u'skills', u'knowledge', u'knowledge', u'xcode'\n",
    "              , u'scripting', u'debugging', u'skills', u'skills', u'knowledge'\n",
    "              , u'disciplines', u'animation', u'networking', u'expertise', u'competencies'\n",
    "              , u'oral', u'skills', u'management', u'skills', u'proven', u'effectively'\n",
    "              , u'teams', u'deadline', u'environment', u'bachelor', u'minimum', u'shipped'\n",
    "              , u'leadership', u'teams', u'location', u'resumes', u'jobs', u'candidates'\n",
    "              , u'openings', u'jobs'],\n",
    "             \n",
    "             [u'maryland', u'client', u'producers', u'electricity'\n",
    "              , u'operates', u'storage', u'utility', u'retail', u'customers', u'engineering'\n",
    "              , u'consultant', u'maryland', u'summary', u'technical', u'technology'\n",
    "              , u'departments', u'expertise', u'maximizing', u'output', u'reduces'\n",
    "              , u'operating', u'participates', u'areas', u'engineering', u'conducts'\n",
    "              , u'testing', u'solve', u'supports', u'environmental', u'understands'\n",
    "              , u'objectives', u'operates', u'responsibilities', u'handles', u'complex'\n",
    "              , u'engineering', u'aspects', u'monitors', u'quality', u'proficiency'\n",
    "              , u'optimization', u'recommendations', u'supports', u'personnel'\n",
    "              , u'troubleshooting', u'commissioning', u'startup', u'shutdown', u'supports'\n",
    "              , u'procedure', u'operating', u'units', u'develops', u'simulations'\n",
    "              , u'troubleshooting', u'tests', u'enhancing', u'solving', u'develops'\n",
    "              , u'estimates', u'schedules', u'scopes', u'understands', u'technical'\n",
    "              , u'management', u'utilize', u'routine', u'conducts', u'hazards', u'utilizing'\n",
    "              , u'hazard', u'operability', u'methodologies', u'participates', u'startup'\n",
    "              , u'reviews', u'pssr', u'participate', u'teams', u'participate', u'regulatory'\n",
    "              , u'audits', u'define', u'scopes', u'budgets', u'schedules', u'technical'\n",
    "              , u'management', u'environmental', u'awareness', u'interfacing', u'personnel'\n",
    "              , u'interacts', u'regulatory', u'departments', u'input', u'objectives'\n",
    "              , u'identifying', u'introducing', u'concepts', u'solutions', u'peers'\n",
    "              , u'customers', u'coworkers', u'knowledge', u'skills', u'engineering'\n",
    "              , u'quality', u'engineering', u'commissioning', u'startup', u'knowledge'\n",
    "              , u'simulators', u'technologies', u'knowledge', u'engineering', u'techniques'\n",
    "              , u'disciplines', u'leadership', u'skills', u'proven', u'engineers', u'oral'\n",
    "              , u'skills', u'technical', u'skills', u'analytically', u'solve', u'complex'\n",
    "              , u'interpret', u'proficiency', u'simulation', u'knowledge', u'applications'\n",
    "              , u'manipulate', u'applications', u'engineering', u'calculations', u'programs'\n",
    "              , u'matlab', u'excel', u'independently', u'environment', u'proven', u'skills'\n",
    "              , u'effectively', u'multiple', u'tasks', u'planning', u'organizational'\n",
    "              , u'management', u'skills', u'rigzone', u'jobs', u'developer', u'exceptional'\n",
    "              , u'strategies', u'junction', u'exceptional', u'strategies', u'solutions'\n",
    "              , u'solutions', u'biggest', u'insurers', u'operates', u'investment']\n",
    "             \n",
    "             , [u'vegas', u'tasks', u'electrical', u'contracting', u'expertise', u'virtually'\n",
    "                , u'electrical', u'developments', u'institutional', u'utilities', u'technical'\n",
    "                , u'experts', u'relationships', u'credibility', u'contractors', u'utility'\n",
    "                , u'customers', u'customer', u'relationships', u'consistently', u'innovations'\n",
    "                , u'profile', u'construct', u'envision', u'dynamic', u'complex', u'electrical'\n",
    "                , u'management', u'grad', u'internship', u'electrical', u'engineering'\n",
    "                , u'infrastructures', u'engineers', u'documented', u'management', u'engineering'\n",
    "                , u'quality', u'engineering', u'electrical', u'engineers', u'complex', u'distribution'\n",
    "                , u'grounding', u'estimation', u'testing', u'procedures', u'voltage', u'engineering'\n",
    "                , u'troubleshooting', u'installation', u'documentation', u'bsee', u'certification'\n",
    "                , u'electrical', u'voltage', u'cabling', u'electrical', u'engineering', u'candidates'\n",
    "                , u'electrical', u'internships', u'oral', u'skills', u'organizational'\n",
    "                , u'prioritization', u'skills', u'skills', u'excel', u'cadd', u'calculation'\n",
    "                , u'autocad', u'mathcad', u'skills', u'skills', u'customer', u'relationships'\n",
    "                , u'solving', u'ethic', u'motivation', u'tasks', u'budget', u'affirmative'\n",
    "                , u'diversity', u'workforce', u'gender', u'orientation', u'disability', u'disabled'\n",
    "                , u'veteran', u'vietnam', u'veteran', u'qualifying', u'veteran', u'diverse'\n",
    "                , u'candidates', u'respond', u'developing', u'workplace', u'reflects'\n",
    "                , u'diversity', u'communities', u'reviews', u'electrical', u'contracting'\n",
    "                , u'southwest', u'electrical', u'contractors']\n",
    "             \n",
    "             , [u'intern', u'electrical', u'engineering', u'idexx', u'laboratories', u'validating'\n",
    "                , u'idexx', u'integrated', u'hardware', u'entails', u'planning', u'debug'\n",
    "                , u'validation', u'engineers', u'validation', u'methodologies', u'healthcare'\n",
    "                , u'platforms', u'brightest', u'solve', u'challenges', u'innovation'\n",
    "                , u'technology', u'idexx', u'intern', u'idexx', u'interns', u'supplement'\n",
    "                , u'interns', u'teams', u'roles', u'competitive', u'interns', u'idexx'\n",
    "                , u'interns', u'participate', u'internships', u'mentors', u'seminars'\n",
    "                , u'topics', u'leadership', u'workshops', u'relevant', u'planning', u'topics'\n",
    "                , u'intern', u'presentations', u'mixers', u'applicants', u'ineligible'\n",
    "                , u'laboratory', u'compliant', u'idexx', u'laboratories', u'healthcare'\n",
    "                , u'innovation', u'practicing', u'veterinarians', u'diagnostic', u'technology'\n",
    "                , u'idexx', u'enhance', u'veterinarians', u'efficiency', u'economically'\n",
    "                , u'idexx', u'worldwide', u'diagnostic', u'tests', u'tests', u'quality'\n",
    "                , u'headquartered', u'idexx', u'laboratories', u'employs', u'customers'\n",
    "                , u'qualifications', u'applicants', u'idexx', u'interns', u'potential'\n",
    "                , u'demonstrated', u'portfolio', u'recommendation', u'resumes', u'marketing'\n",
    "                , u'location', u'americas', u'verification', u'validation', u'schedule'\n",
    "                , u'overtime', u'idexx', u'laboratories', u'reviews', u'idexx', u'laboratories'\n",
    "                , u'nasdaq', u'healthcare', u'innovation', u'practicing', u'veterinarians']\n",
    "             \n",
    "             , [u'location', u'duration', u'temp', u'verification', u'validation', u'tester'\n",
    "                , u'verification', u'validation', u'middleware', u'specifically', u'testing'\n",
    "                , u'applications', u'clinical', u'laboratory', u'regulated', u'environment'\n",
    "                , u'responsibilities', u'complex', u'hardware', u'testing', u'clinical'\n",
    "                , u'analyzers', u'laboratory', u'graphical', u'interfaces', u'complex'\n",
    "                , u'sample', u'sequencing', u'protocols', u'developers', u'correction'\n",
    "                , u'tracking', u'tool', u'timely', u'troubleshoot', u'testing', u'functional'\n",
    "                , u'manual', u'automated', u'participate', u'ongoing', u'testing', u'coverage'\n",
    "                , u'planning', u'documentation', u'testing', u'validation', u'corrections'\n",
    "                , u'monitor', u'implementation', u'recurrence', u'operating', u'statistical'\n",
    "                , u'quality', u'testing', u'global', u'multi', u'teams', u'travel', u'skills'\n",
    "                , u'concepts', u'waterfall', u'agile', u'methodologies', u'debugging'\n",
    "                , u'skills', u'complex', u'automated', u'instrumentation', u'environment'\n",
    "                , u'hardware', u'mechanical', u'components', u'tracking', u'lifecycle'\n",
    "                , u'management', u'quality', u'organize', u'define', u'priorities'\n",
    "                , u'organize', u'supervision', u'aggressive', u'deadlines', u'ambiguity'\n",
    "                , u'analyze', u'complex', u'situations', u'concepts', u'technologies'\n",
    "                , u'verbal', u'skills', u'effectively', u'technical', u'clinical'\n",
    "                , u'diverse', u'strategy', u'clinical', u'chemistry', u'analyzer'\n",
    "                , u'laboratory', u'middleware', u'basic', u'automated', u'testing'\n",
    "                , u'biomedical', u'engineering', u'technologists', u'laboratory'\n",
    "                , u'technology', u'availability', u'click', u'attach']\n",
    "             \n",
    "             ,[u'scientist', u'linux', u'asrc', u'scientist', u'linux', u'asrc'\n",
    "               , u'technology', u'solutions', u'subsidiary', u'asrc', u'engineering'\n",
    "               , u'technology', u'contracts', u'multiple', u'agencies', u'scientists'\n",
    "               , u'engineers', u'management', u'personnel', u'allows', u'solutions'\n",
    "               , u'complex', u'aeronautics', u'aviation', u'management', u'aviation'\n",
    "               , u'engineering', u'hughes', u'technical', u'technical', u'aviation'\n",
    "               , u'evaluation', u'engineering', u'management', u'technical', u'terminal'\n",
    "               , u'surveillance', u'programs', u'currently', u'scientist', u'travel'\n",
    "               , u'responsibilities', u'develops', u'technology', u'modifies'\n",
    "               , u'technical', u'complex', u'reviews', u'draft', u'conformity'\n",
    "               , u'completeness', u'testing', u'interface', u'hardware', u'regression'\n",
    "               , u'impact', u'reliability', u'maintainability', u'factors'\n",
    "               , u'standardization', u'skills', u'travel', u'programming'\n",
    "               , u'linux', u'environment', u'cisco', u'knowledge', u'terminal'\n",
    "               , u'environment', u'clearance', u'clearance', u'input', u'output'\n",
    "               , u'digital', u'automatic', u'terminal', u'management', u'controller'\n",
    "               , u'termination', u'testing', u'evaluating', u'policies', u'procedure'\n",
    "               , u'interface', u'installation', u'verification', u'certification'\n",
    "               , u'core', u'avionic', u'programs', u'knowledge', u'procedural'\n",
    "               , u'testing', u'interfacing', u'hardware', u'regression', u'impact'\n",
    "               , u'reliability', u'maintainability', u'factors', u'standardization'\n",
    "               , u'missions', u'asrc', u'subsidiaries', u'affirmative', u'employers'\n",
    "               , u'applicants', u'disability', u'veteran', u'technology', u'location'\n",
    "               , u'airport', u'bachelor', u'schedule', u'travel', u'contributor'\n",
    "               , u'management', u'asrc', u'reviews']\n",
    "             \n",
    "             , [u'technical', u'solarcity', u'niche', u'vegas', u'overview'\n",
    "                , u'resolving', u'customer', u'clients', u'expanding', u'engineers'\n",
    "                , u'developers', u'responsibilities', u'knowledge', u'planning'\n",
    "                , u'adapt', u'dynamic', u'environment', u'inventive', u'creative'\n",
    "                , u'solarcity', u'lifecycle', u'responsibilities', u'technical'\n",
    "                , u'analyzing', u'diagnosing', u'troubleshooting', u'customers'\n",
    "                , u'ticketing', u'console', u'escalate', u'knowledge', u'engineering'\n",
    "                , u'timely', u'basic', u'phone', u'functionality', u'customer'\n",
    "                , u'tracking', u'knowledgebase', u'rotation', u'configure'\n",
    "                , u'deployment', u'sccm', u'technical', u'deployment', u'deploy'\n",
    "                , u'hardware', u'solarcity', u'bachelor', u'knowledge', u'dell'\n",
    "                , u'laptops', u'analytical', u'troubleshooting', u'solving'\n",
    "                , u'skills', u'knowledge', u'databases', u'preferably', u'server'\n",
    "                , u'preferably', u'monitoring', u'suites', u'documentation'\n",
    "                , u'procedures', u'knowledge', u'entries', u'verbal', u'skills'\n",
    "                , u'customer', u'skills', u'competitive', u'solar', u'package'\n",
    "                , u'insurance', u'vacation', u'savings', u'referral', u'eligibility'\n",
    "                , u'equity', u'performers', u'solarcity', u'affirmative'\n",
    "                , u'diversity', u'workplace', u'applicants', u'orientation'\n",
    "                , u'disability', u'veteran', u'careerrookie']\n",
    "             \n",
    "             , [u'embedded', u'exelis', u'junction', u'exelis', u'embedded'\n",
    "                , u'acquisition', u'networking', u'capabilities', u'classified'\n",
    "                , u'customer', u'motivated', u'develops', u'tests', u'innovative'\n",
    "                , u'solutions', u'minimal', u'supervision', u'paced', u'environment'\n",
    "                , u'enjoys', u'assignments', u'interact', u'multi', u'disciplined'\n",
    "                , u'challenging', u'focused', u'embedded', u'developments'\n",
    "                , u'spanning', u'engineering', u'lifecycle', u'specification'\n",
    "                , u'enhancement', u'applications', u'embedded', u'freescale'\n",
    "                , u'applications', u'android', u'platforms', u'interface'\n",
    "                , u'customers', u'developers', u'refine', u'specifications'\n",
    "                , u'architectures', u'java', u'programming', u'scripts'\n",
    "                , u'python', u'debug', u'debugging', u'emulators', u'regression'\n",
    "                , u'revisions', u'specialized', u'setups', u'capabilities'\n",
    "                , u'subversion', u'technical', u'documentation', u'multiple'\n",
    "                , u'engineering', u'techexpousa', u'reviews']\n",
    "             \n",
    "             , [u'modeler', u'semantic', u'modeling', u'models', u'skills', u'ontology'\n",
    "                , u'resource', u'framework', u'schema', u'technologies', u'hadoop'\n",
    "                , u'warehouse', u'oracle', u'relational', u'artifacts', u'models'\n",
    "                , u'dictionaries', u'models', u'interface', u'specifications'\n",
    "                , u'documentation', u'harmonization', u'mappings', u'aligned'\n",
    "                , u'coordinate', u'technical', u'peer', u'reviews', u'stakeholder'\n",
    "                , u'communities', u'impact', u'domains', u'relationships'\n",
    "                , u'interdependencies', u'models', u'define', u'analyze', u'legacy'\n",
    "                , u'models', u'corporate', u'databases', u'architectural', u'alignment'\n",
    "                , u'customer', u'expertise', u'harmonization', u'modeling', u'modeling'\n",
    "                , u'consulting', u'stakeholders', u'quality', u'models', u'storage'\n",
    "                , u'agile', u'specifically', u'focus', u'modeling', u'qualifications'\n",
    "                , u'bachelors', u'accredited', u'modeler', u'encompass', u'evaluation'\n",
    "                , u'skills', u'knowledge', u'modeling', u'techniques', u'resource'\n",
    "                , u'framework', u'schema', u'technologies', u'unified', u'modeling'\n",
    "                , u'technologies', u'schemas', u'ontologies', u'sybase', u'knowledge'\n",
    "                , u'skills', u'interpersonal', u'skills', u'customers', u'clearance'\n",
    "                , u'applicants', u'eligibility', u'classified', u'clearance', u'polygraph'\n",
    "                , u'techexpousa', u'solutions', u'partnership', u'solutions', u'integration']\n",
    "             \n",
    "             , [u'technologies', u'junction', u'develops', u'maintains', u'enhances'\n",
    "                , u'complex', u'diverse', u'intensive', u'analytics', u'algorithm'\n",
    "                , u'manipulation', u'management', u'documented', u'individually'\n",
    "                , u'reviews', u'tests', u'components', u'adherence', u'resolves'\n",
    "                , u'utilizes', u'methodologies', u'environment', u'input', u'components'\n",
    "                , u'hardware', u'offs', u'reuse', u'cots', u'gots', u'synthesis'\n",
    "                , u'components', u'tasks', u'individually', u'analyzes', u'modifies'\n",
    "                , u'debugs', u'corrects', u'integrates', u'operating', u'environments'\n",
    "                , u'develops', u'queries', u'databases', u'repositories', u'recommendations'\n",
    "                , u'improving', u'documentation', u'develops', u'implements', u'algorithms'\n",
    "                , u'functional', u'assists', u'developing', u'executing', u'procedures'\n",
    "                , u'components', u'reviews', u'documentation', u'solutions', u'analyzing'\n",
    "                , u'conferring', u'users', u'engineers', u'analyzing', u'investigating'\n",
    "                , u'areas', u'adapt', u'hardware', u'mathematical', u'models', u'predict'\n",
    "                , u'outcome', u'implement', u'complex', u'database', u'repository'\n",
    "                , u'interfaces', u'queries', u'bachelors', u'accredited', u'substituted'\n",
    "                , u'bachelors', u'firewalls', u'ipsec', u'vpns', u'technology'\n",
    "                , u'administering', u'servers', u'apache', u'jboss', u'tomcat'\n",
    "                , u'developing', u'interfaces', u'firefox', u'internet', u'explorer'\n",
    "                , u'operating', u'mainframe', u'linux', u'solaris', u'virtual'\n",
    "                , u'scripting', u'programming', u'oriented', u'programming', u'ajax'\n",
    "                , u'script', u'procedures', u'cobol', u'cognos', u'fusion', u'focus'\n",
    "                , u'html', u'java', u'java', u'script', u'jquery', u'perl', u'visual'\n",
    "                , u'basic', u'powershell', u'cots', u'cots', u'oracle', u'apex'\n",
    "                , u'integration', u'competitive', u'package', u'bonus', u'corporate'\n",
    "                , u'equity', u'tuition', u'reimbursement', u'referral', u'bonus'\n",
    "                , u'holidays', u'insurance', u'flexible', u'disability', u'insurance'\n",
    "                , u'technologies', u'disability', u'accommodation', u'recruiter', u'techexpousa']\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.textcorpus:Initializing dictionary\n",
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(546 unique tokens: ['animation', 'award', 'bachelor', 'bugs', 'candidates']...) from 10 documents (total 1112 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "dtm_corpus = DTMcorpus(test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_seq = [3, 7]  # first 3 documents are from time slice one \n",
    "#  and the other 7 are from the second time slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.DTMcorpus"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dtm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.wrappers.dtmmodel:serializing temporary corpus to /var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train-mult.dat\n",
      "INFO:gensim.corpora.bleicorpus:no word id mapping provided; initializing from corpus\n",
      "INFO:gensim.corpora.bleicorpus:storing corpus in Blei's LDA-C format into /var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train-mult.dat\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'wb', 'uri': '/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train-mult.dat'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'wb', 'fileobj': <_io.BufferedWriter name='/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train-mult.dat'>}\n",
      "INFO:gensim.corpora.bleicorpus:saving vocabulary of 546 words to /var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train-mult.dat.vocab\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'wb', 'uri': '/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train-mult.dat.vocab'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'wb', 'fileobj': <_io.BufferedWriter name='/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train-mult.dat.vocab'>}\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'wb', 'uri': '/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train-seq.dat'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'wb', 'fileobj': <_io.BufferedWriter name='/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train-seq.dat'>}\n",
      "INFO:gensim.models.wrappers.dtmmodel:training DTM with args --ntopics=20 --model=dtm  --mode=fit --initialize_lda=true --corpus_prefix=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train --outname=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train_out --alpha=0.01 --lda_max_em_iter=10 --lda_sequence_min_iter=6  --lda_sequence_max_iter=20 --top_chain_var=0.005 --rng_seed=0 \n",
      "INFO:gensim.models.wrappers.dtmmodel:Running command ['/Users/jmc/src/dtm/dtm_release/dtm/main', '--ntopics=20', '--model=dtm', '--mode=fit', '--initialize_lda=true', '--corpus_prefix=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train', '--outname=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train_out', '--alpha=0.01', '--lda_max_em_iter=10', '--lda_sequence_min_iter=6', '--lda_sequence_max_iter=20', '--top_chain_var=0.005', '--rng_seed=0']\n",
      "DEBUG:gensim.utils:COMMAND: () {'args': ['/Users/jmc/src/dtm/dtm_release/dtm/main', '--ntopics=20', '--model=dtm', '--mode=fit', '--initialize_lda=true', '--corpus_prefix=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train', '--outname=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/ec66ae_train_out', '--alpha=0.01', '--lda_max_em_iter=10', '--lda_sequence_min_iter=6', '--lda_sequence_max_iter=20', '--top_chain_var=0.005', '--rng_seed=0'], 'stderr': -1}\n"
     ]
    }
   ],
   "source": [
    "dtm_model = DtmModel(DTM_PATH\n",
    "                  , dtm_corpus\n",
    "                  , time_seq\n",
    "                  , num_topics=20\n",
    "                  , id2word=dtm_corpus.dictionary\n",
    "                  , initialize_lda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Topic 0 0.000060\n",
      "Distribution of Topic 1 0.000060\n"
     ]
    }
   ],
   "source": [
    "doc_number = 1\n",
    "num_topics = 2\n",
    "\n",
    "for i in range(0, num_topics):\n",
    "    print (\"Distribution of Topic %d %f\" % (i, dtm_model.gamma_[doc_number, i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIM Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.wrappers.dtmmodel:serializing temporary corpus to /var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train-mult.dat\n",
      "INFO:gensim.corpora.bleicorpus:no word id mapping provided; initializing from corpus\n",
      "INFO:gensim.corpora.bleicorpus:storing corpus in Blei's LDA-C format into /var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train-mult.dat\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'wb', 'uri': '/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train-mult.dat'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'wb', 'fileobj': <_io.BufferedWriter name='/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train-mult.dat'>}\n",
      "INFO:gensim.corpora.bleicorpus:saving vocabulary of 546 words to /var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train-mult.dat.vocab\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'wb', 'uri': '/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train-mult.dat.vocab'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'wb', 'fileobj': <_io.BufferedWriter name='/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train-mult.dat.vocab'>}\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'wb', 'uri': '/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train-seq.dat'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'wb', 'fileobj': <_io.BufferedWriter name='/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train-seq.dat'>}\n",
      "INFO:gensim.models.wrappers.dtmmodel:training DTM with args --ntopics=2 --model=fixed  --mode=fit --initialize_lda=true --corpus_prefix=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train --outname=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train_out --alpha=0.01 --lda_max_em_iter=10 --lda_sequence_min_iter=6  --lda_sequence_max_iter=20 --top_chain_var=0.005 --rng_seed=0 \n",
      "INFO:gensim.models.wrappers.dtmmodel:Running command ['/Users/jmc/src/dtm/dtm_release/dtm/main', '--ntopics=2', '--model=fixed', '--mode=fit', '--initialize_lda=true', '--corpus_prefix=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train', '--outname=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train_out', '--alpha=0.01', '--lda_max_em_iter=10', '--lda_sequence_min_iter=6', '--lda_sequence_max_iter=20', '--top_chain_var=0.005', '--rng_seed=0']\n",
      "DEBUG:gensim.utils:COMMAND: () {'args': ['/Users/jmc/src/dtm/dtm_release/dtm/main', '--ntopics=2', '--model=fixed', '--mode=fit', '--initialize_lda=true', '--corpus_prefix=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train', '--outname=/var/folders/s2/y23_8q5n12d343lf0z44j9mm0000gn/T/a998b1_train_out', '--alpha=0.01', '--lda_max_em_iter=10', '--lda_sequence_min_iter=6', '--lda_sequence_max_iter=20', '--top_chain_var=0.005', '--rng_seed=0'], 'stderr': -1}\n"
     ]
    }
   ],
   "source": [
    "dim_model = DtmModel(DTM_PATH, dtm_corpus, time_seq, num_topics=2,\n",
    "                 id2word=dtm_corpus.dictionary, initialize_lda=True, model='fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008210686237285747"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_no = 1 #document 2\n",
    "topic_no = 1 #topic number 2\n",
    "time_slice = 0 #time slice 1\n",
    "\n",
    "dim_model.influences_time[time_slice][document_no][topic_no]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
